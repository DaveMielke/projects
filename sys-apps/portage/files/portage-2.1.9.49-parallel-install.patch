commit 8e8647abbaab948273aa1b82a7718c93ed959830
Author: David James <davidjames@chromium.org>
Date:   Fri May 6 21:53:31 2011 -0700

    Use finer grained locks for install.
    
    Narrow scope of merge locks to improve performance.
    
    Instead of locking the DB for the entire package merge, just lock it
    when we actually need to do so. Also add locks around conf_mem_file
    updating and pkg_* phases.
    
    Locking in pkg_* phases can be turned off with
    FEATURES="no-ebuild-locks" if you use ebuilds that are careful not
    to mess with each other during theses phases. The default is to leave
    this locking enabled.
    
    Given this new locking, I've improved the scheduler to run merge jobs
    in parallel.
    
    Time required for merging 348 packages with --usepkgonly:
      - Before patch:          29m50s
      - After patch:           10m2s
      - After patch w/o locks: 7m9s
    
    Change-Id: I63588c4cc59fa6fe2f8327ea1e4a9e71b241d4fe
    
    Review URL: http://gerrit.chromium.org/gerrit/498
    
    Rename FEATURES=no-ebuild-locks to ebuild-locks.
    (cherry picked from commit e414b8571fed1e0da1a03e0a9719b580e21f7558)
    
    vardbapi: acquire lock during counter_tick_core
    (cherry picked from commit bc5d73fa3db0569c55d48c2e738f12742579536c)
    
    Add FEATURES=parallel-install for finer locks.
    
    Change-Id: Id2f82aee4bd1a3abec5eadcc837634f6f11d92e7
    
    Scheduler: add queue for ebuild-locks
    
    Use a separate queue for ebuild-locks when the merge
    queue allows more than 1 job (due to parallel-install),
    since the portage.locks module does not behave as desired
    if we try to lock the same file multiple times
    concurrently from the same process.
    (cherry picked from commit a81460175a441897282b0540cefff8060f2b92dc)
    
    Use EROOT with VDB_PATH in recent changes.
    (cherry picked from commit 36ad74b36d6d70a21d24ef7cb180ab09a6a327f0)
    
    linkmap: check for access before locking vardbapi
    (cherry picked from commit 6d916753c07ccad4fcc596b155d776f297aeeb68)
    
    Fix typos in unmerge function.
    
    BUG=none
    TEST=Try unmerging some packages.
    
    Change-Id: Ib643ec95b8da14b49a6b519e445fe57f8995c52c
    (cherry picked from commit 05b16b9d1c4eacc3442b78152f46f5d07943de97)
    
    LinkageMapELF: remove unused imports
    (cherry picked from commit 125430a3f2879e4bc497be212a91d9dd7194d261)
    
    vardbapi: add reentrant _fs_lock/unlock methods
    (cherry picked from commit 39b034d11b8a3118e8c1cfc6f6d06df43e5efa35)
    
    preserve-libs: use vardbapi _fs_lock/unlock
    
    The preserve-libs code is too dependent on the filesystem state to
    allow merging/unmerge/env_update to execute concurrently.
    (cherry picked from commit 03d2647d5c8d74088b29283598f8c4a0fef5db96)
    
    movefile: handle EEXIST when os.symlink fails
    (cherry picked from commit 5fc6f2b77d853eec51d6dbdfbfecc5dd7c5b5648)
    
    Use vardbapi.lock() where applicable.
    (cherry picked from commit 80145998591fc0dc51ab4a96a279fed40a04345a)
    
    EbuildPhase: AsynchronousLock for ebuild-locks
    (cherry picked from commit f3f88c6a3695755aafa3765219fa323fe46679d6)
    
    EbuildPhase: fix locking for setup phase
    (cherry picked from commit 102006ae93b32fc20f6c9324e2e90252277ee5b1)
    
    EbuildMerge: inherit from CompositeTask
    (cherry picked from commit 33a3a2d9cdc44e07aaece8fdf08a3d3bde6e5d82)
    
    treewalk: unlockdb/lockdb typo triggers EDEADLK
    (cherry picked from commit 8380ec9d7590a47b912e0d1e1db2ebb6049b903b)
    
    _LockProcess: handle process failure if cancelled
    (cherry picked from commit 0ee4c2b7195e03c828dc4f1ef85825509a5fe77a)
    
    _LockProcess: handle process failure more
    (cherry picked from commit 4ca3a0de43b6a7093f97330a31a76320db53f3f7)
    
    EbuildBuildDir: handle AsynchronousLock failure
    (cherry picked from commit aeaa86486d9ea5a799c49bf8baa9a24a87ccb4de)
    
    BinpkgFetcher: handle AsynchronousLock failure
    (cherry picked from commit e26008ef6eea54c04d3fe62a0e657e4a4581025a)

diff --git a/cnf/make.globals b/cnf/make.globals
index 65056d1..7c5fbb8 100644
--- a/cnf/make.globals
+++ b/cnf/make.globals
@@ -51,7 +51,7 @@ RESUMECOMMAND_SSH=${FETCHCOMMAND_SSH}
 FETCHCOMMAND_SFTP="bash -c \"x=\\\${2#sftp://} ; host=\\\${x%%/*} ; port=\\\${host##*:} ; host=\\\${host%:*} ; [[ \\\${host} = \\\${port} ]] && port=22 ; exec sftp -P \\\${port} \\\"\\\${host}:/\\\${x#*/}\\\" \\\"\\\$1\\\"\" sftp \"\${DISTDIR}/\${FILE}\" \"\${URI}\""
 
 # Default user options
-FEATURES="assume-digests binpkg-logs distlocks fixpackages
+FEATURES="assume-digests binpkg-logs distlocks ebuild-locks fixpackages
           fixlafiles news parallel-fetch protect-owned
           sandbox sfperms strict unknown-features-warn unmerge-logs
           unmerge-orphans userfetch"
diff --git a/man/make.conf.5 b/man/make.conf.5
index 53b2c29..305ba26 100644
--- a/man/make.conf.5
+++ b/man/make.conf.5
@@ -1,4 +1,4 @@
-.TH "MAKE.CONF" "5" "Apr 2011" "Portage VERSION" "Portage"
+.TH "MAKE.CONF" "5" "May 2011" "Portage VERSION" "Portage"
 .SH "NAME"
 make.conf \- custom settings for Portage
 .SH "SYNOPSIS"
@@ -265,6 +265,10 @@ strangely configured Samba server (oplocks off, NFS re\-export). A tool
 /usr/lib/portage/bin/clean_locks exists to help handle lock issues
 when a problem arises (normally due to a crash or disconnect).
 .TP
+.B ebuild\-locks
+Use locks to ensure that unsandboxed ebuild phases never execute
+concurrently. Also see \fIparallel\-install\fR.
+.TP
 .B fakeroot
 Enable fakeroot for the install and package phases when a non-root user runs
 the \fBebuild\fR(1) command.
@@ -369,6 +373,11 @@ Fetch in the background while compiling. Run
 `tail \-f /var/log/emerge\-fetch.log` in a
 terminal to view parallel-fetch progress.
 .TP
+.B parallel\-install
+Use finer\-grained locks when installing packages, allowing for greater
+parallelization. For additional parallelization, disable
+\fIebuild\-locks\fR.
+.TP
 .B parse\-eapi\-ebuild\-head
 Parse \fBEAPI\fR from the head of the ebuild (first 30 lines). This feature
 is only intended for experimental purposes and should not be enabled under
diff --git a/pym/_emerge/AsynchronousLock.py b/pym/_emerge/AsynchronousLock.py
index 6fa2bf6..1135df7 100644
--- a/pym/_emerge/AsynchronousLock.py
+++ b/pym/_emerge/AsynchronousLock.py
@@ -3,6 +3,7 @@
 
 import dummy_threading
 import fcntl
+import logging
 import sys
 
 try:
@@ -13,7 +14,9 @@ except ImportError:
 import portage
 from portage import os
 from portage.exception import TryAgain
+from portage.localization import _
 from portage.locks import lockfile, unlockfile
+from portage.util import writemsg_level
 from _emerge.AbstractPollTask import AbstractPollTask
 from _emerge.AsynchronousTask import AsynchronousTask
 from _emerge.PollConstants import PollConstants
@@ -176,7 +179,7 @@ class _LockProcess(AbstractPollTask):
 	"""
 
 	__slots__ = ('path', 'scheduler',) + \
-		('_proc', '_files', '_reg_id')
+		('_acquired', '_proc', '_files', '_reg_id', '_unlocked')
 
 	def _start(self):
 		in_pr, in_pw = os.pipe()
@@ -202,9 +205,28 @@ class _LockProcess(AbstractPollTask):
 
 	def _proc_exit(self, proc):
 		if proc.returncode != os.EX_OK:
-			# There's no good reason for locks to fail.
-			raise AssertionError('lock process failed with returncode %s' \
-				% (proc.returncode,))
+			# Typically, this will happen due to the
+			# process being killed by a signal.
+			if not self._acquired:
+				# If the lock hasn't been aquired yet, the
+				# caller can check the returncode and handle
+				# this failure appropriately.
+				if not self.cancelled:
+					writemsg_level("_LockProcess: %s\n" % \
+						_("failed to acquire lock on '%s'") % (self.path,),
+						level=logging.ERROR, noiselevel=-1)
+				self._unregister()
+				self.returncode = proc.returncode
+				self.wait()
+				return
+
+			if not self.cancelled and \
+				not self._unlocked:
+				# We don't want lost locks going unnoticed, so it's
+				# only safe to ignore if either the cancel() or
+				# unlock() methods have been previously called.
+				raise AssertionError("lock process failed with returncode %s" \
+					% (proc.returncode,))
 
 	def _cancel(self):
 		if self._proc is not None:
@@ -220,6 +242,7 @@ class _LockProcess(AbstractPollTask):
 	def _output_handler(self, f, event):
 		buf = self._read_buf(self._files['pipe_in'], event)
 		if buf:
+			self._acquired = True
 			self._unregister()
 			self.returncode = os.EX_OK
 			self.wait()
@@ -244,6 +267,7 @@ class _LockProcess(AbstractPollTask):
 			raise AssertionError('not locked')
 		if self.returncode is None:
 			raise AssertionError('lock not acquired yet')
+		self._unlocked = True
 		self._files['pipe_out'].write(b'\0')
 		self._files['pipe_out'].close()
 		self._files = None
diff --git a/pym/_emerge/Binpkg.py b/pym/_emerge/Binpkg.py
index bc6b85d..1ed5c1f 100644
--- a/pym/_emerge/Binpkg.py
+++ b/pym/_emerge/Binpkg.py
@@ -315,12 +315,11 @@ class Binpkg(CompositeTask):
 		settings["PORTAGE_BINPKG_FILE"] = self._pkg_path
 		settings.backup_changes("PORTAGE_BINPKG_FILE")
 
-		merge = EbuildMerge(find_blockers=self.find_blockers,
+		task = EbuildMerge(find_blockers=self.find_blockers,
 			ldpath_mtimes=self.ldpath_mtimes, logger=self.logger,
 			pkg=self.pkg, pkg_count=self.pkg_count,
 			pkg_path=self._pkg_path, scheduler=self.scheduler,
 			settings=settings, tree=self._tree, world_atom=self.world_atom)
-		task = merge.create_task()
 		task.addExitListener(self._install_exit)
 		return task
 
diff --git a/pym/_emerge/BinpkgFetcher.py b/pym/_emerge/BinpkgFetcher.py
index 221d9a7..12544d1 100644
--- a/pym/_emerge/BinpkgFetcher.py
+++ b/pym/_emerge/BinpkgFetcher.py
@@ -158,7 +158,12 @@ class BinpkgFetcher(SpawnProcess):
 		async_lock = AsynchronousLock(path=self.pkg_path,
 			scheduler=self.scheduler)
 		async_lock.start()
-		async_lock.wait()
+
+		if async_lock.wait() != os.EX_OK:
+			# TODO: Use CompositeTask for better handling, like in EbuildPhase.
+			raise AssertionError("AsynchronousLock failed with returncode %s" \
+				% (async_lock.returncode,))
+
 		self._lock_obj = async_lock
 		self.locked = True
 
diff --git a/pym/_emerge/EbuildBuild.py b/pym/_emerge/EbuildBuild.py
index c33153b..3999d20 100644
--- a/pym/_emerge/EbuildBuild.py
+++ b/pym/_emerge/EbuildBuild.py
@@ -330,7 +330,7 @@ class EbuildBuild(CompositeTask):
 		ebuild_path = self._ebuild_path
 		tree = self._tree
 
-		merge = EbuildMerge(find_blockers=self.find_blockers,
+		task = EbuildMerge(find_blockers=self.find_blockers,
 			ldpath_mtimes=ldpath_mtimes, logger=logger, pkg=pkg,
 			pkg_count=pkg_count, pkg_path=ebuild_path,
 			scheduler=self.scheduler,
@@ -343,7 +343,6 @@ class EbuildBuild(CompositeTask):
 			(pkg_count.curval, pkg_count.maxval, pkg.cpv)
 		logger.log(msg, short_msg=short_msg)
 
-		task = merge.create_task()
 		task.addExitListener(self._install_exit)
 		return task
 
diff --git a/pym/_emerge/EbuildBuildDir.py b/pym/_emerge/EbuildBuildDir.py
index 1da3c93..3e0aefb 100644
--- a/pym/_emerge/EbuildBuildDir.py
+++ b/pym/_emerge/EbuildBuildDir.py
@@ -43,6 +43,8 @@ class EbuildBuildDir(SlotObject):
 		catdir_lock = AsynchronousLock(path=catdir, scheduler=self.scheduler)
 		catdir_lock.start()
 		catdir_lock.wait()
+		self._assert_lock(catdir_lock)
+
 		try:
 			try:
 				portage.util.ensure_dirs(catdir,
@@ -55,12 +57,19 @@ class EbuildBuildDir(SlotObject):
 				scheduler=self.scheduler)
 			builddir_lock.start()
 			builddir_lock.wait()
+			self._assert_lock(builddir_lock)
 			self._lock_obj = builddir_lock
 			self.settings['PORTAGE_BUILDIR_LOCKED'] = '1'
 		finally:
 			self.locked = self._lock_obj is not None
 			catdir_lock.unlock()
 
+	def _assert_lock(self, async_lock):
+		if async_lock.returncode != os.EX_OK:
+			# TODO: create a better way to propagate this error to the caller
+			raise AssertionError("AsynchronousLock failed with returncode %s" \
+				% (async_lock.returncode,))
+
 	def clean_log(self):
 		"""Discard existing log. The log will not be be discarded
 		in cases when it would not make sense, like when FEATURES=keepwork
@@ -85,15 +94,15 @@ class EbuildBuildDir(SlotObject):
 		self.settings.pop('PORTAGE_BUILDIR_LOCKED', None)
 		catdir_lock = AsynchronousLock(path=self._catdir, scheduler=self.scheduler)
 		catdir_lock.start()
-		catdir_lock.wait()
-		try:
-			os.rmdir(self._catdir)
-		except OSError as e:
-			if e.errno not in (errno.ENOENT,
-				errno.ENOTEMPTY, errno.EEXIST, errno.EPERM):
-				raise
-		finally:
-			catdir_lock.unlock()
+		if catdir_lock.wait() == os.EX_OK:
+			try:
+				os.rmdir(self._catdir)
+			except OSError as e:
+				if e.errno not in (errno.ENOENT,
+					errno.ENOTEMPTY, errno.EEXIST, errno.EPERM):
+					raise
+			finally:
+				catdir_lock.unlock()
 
 	class AlreadyLocked(portage.exception.PortageException):
 		pass
diff --git a/pym/_emerge/EbuildMerge.py b/pym/_emerge/EbuildMerge.py
index 6a58692..5c06d3b 100644
--- a/pym/_emerge/EbuildMerge.py
+++ b/pym/_emerge/EbuildMerge.py
@@ -1,26 +1,24 @@
 # Copyright 1999-2009 Gentoo Foundation
 # Distributed under the terms of the GNU General Public License v2
 
-from _emerge.SlotObject import SlotObject
-import portage
+from _emerge.CompositeTask import CompositeTask
 from portage import os
 from portage.dbapi._MergeProcess import MergeProcess
 from portage.dbapi.vartree import dblink
 
-class EbuildMerge(SlotObject):
+class EbuildMerge(CompositeTask):
 
 	__slots__ = ("find_blockers", "logger", "ldpath_mtimes",
 		"pkg", "pkg_count", "pkg_path", "pretend",
-		"scheduler", "settings", "tree", "world_atom")
+		"settings", "tree", "world_atom")
 
-	def create_task(self):
+	def _start(self):
 		root_config = self.pkg.root_config
 		settings = self.settings
 		mycat = settings["CATEGORY"]
 		mypkg = settings["PF"]
 		pkgloc = settings["D"]
 		infloc = os.path.join(settings["PORTAGE_BUILDDIR"], "build-info")
-		myroot = root_config.root
 		myebuild = settings["EBUILD"]
 		mydbapi = root_config.trees[self.tree].dbapi
 		vartree = root_config.trees["vartree"]
@@ -33,11 +31,12 @@ class EbuildMerge(SlotObject):
 			background=background, blockers=self.find_blockers, pkgloc=pkgloc,
 			infloc=infloc, myebuild=myebuild, mydbapi=mydbapi,
 			prev_mtimes=self.ldpath_mtimes, logfile=logfile)
-		merge_task.addExitListener(self._log_exit)
-		return merge_task
 
-	def _log_exit(self, task):
-		if task.returncode != os.EX_OK:
+		self._start_task(merge_task, self._merge_exit)
+
+	def _merge_exit(self, merge_task):
+		if self._final_exit(merge_task) != os.EX_OK:
+			self.wait()
 			return
 
 		pkg = self.pkg
@@ -55,3 +54,4 @@ class EbuildMerge(SlotObject):
 		logger.log(" ::: completed emerge (%s of %s) %s to %s" % \
 			(pkg_count.curval, pkg_count.maxval, pkg.cpv, pkg.root))
 
+		self.wait()
diff --git a/pym/_emerge/EbuildPhase.py b/pym/_emerge/EbuildPhase.py
index 8bab7ab..db1d59e 100644
--- a/pym/_emerge/EbuildPhase.py
+++ b/pym/_emerge/EbuildPhase.py
@@ -5,6 +5,7 @@ import gzip
 import sys
 import tempfile
 
+from _emerge.AsynchronousLock import AsynchronousLock
 from _emerge.BinpkgEnvExtractor import BinpkgEnvExtractor
 from _emerge.MiscFunctionsProcess import MiscFunctionsProcess
 from _emerge.EbuildProcess import EbuildProcess
@@ -28,7 +29,8 @@ from portage import _unicode_encode
 
 class EbuildPhase(CompositeTask):
 
-	__slots__ = ("actionmap", "phase", "settings")
+	__slots__ = ("actionmap", "phase", "settings") + \
+		("_ebuild_lock",)
 
 	# FEATURES displayed prior to setup phase
 	_features_display = ("ccache", "distcc", "fakeroot",
@@ -37,6 +39,9 @@ class EbuildPhase(CompositeTask):
 		"splitdebug", "suidctl", "test", "userpriv",
 		"usersandbox")
 
+	# Locked phases
+	_locked_phases = ("setup", "preinst", "postinst", "prerm", "postrm")
+
 	def _start(self):
 
 		need_builddir = self.phase not in EbuildProcess._phases_without_builddir
@@ -108,13 +113,32 @@ class EbuildPhase(CompositeTask):
 			# If the environment.bz2 doesn't exist, then ebuild.sh will
 			# source the ebuild as a fallback.
 
-		self._start_ebuild()
+		self._start_lock()
 
 	def _env_extractor_exit(self, env_extractor):
 		if self._default_exit(env_extractor) != os.EX_OK:
 			self.wait()
 			return
 
+		self._start_lock()
+
+	def _start_lock(self):
+		if (self.phase in self._locked_phases and
+			"ebuild-locks" in self.settings.features):
+			eroot = self.settings["EROOT"]
+			lock_path = os.path.join(eroot, portage.VDB_PATH + "-ebuild")
+			if os.access(os.path.dirname(lock_path), os.W_OK):
+				self._ebuild_lock = AsynchronousLock(path=lock_path,
+					scheduler=self.scheduler)
+				self._start_task(self._ebuild_lock, self._lock_exit)
+				return
+
+		self._start_ebuild()
+
+	def _lock_exit(self, ebuild_lock):
+		if self._default_exit(ebuild_lock) != os.EX_OK:
+			self.wait()
+			return
 		self._start_ebuild()
 
 	def _start_ebuild(self):
@@ -142,6 +166,10 @@ class EbuildPhase(CompositeTask):
 
 	def _ebuild_exit(self, ebuild_process):
 
+		if self._ebuild_lock is not None:
+			self._ebuild_lock.unlock()
+			self._ebuild_lock = None
+
 		fail = False
 		if self._default_exit(ebuild_process) != os.EX_OK:
 			if self.phase == "test" and \
diff --git a/pym/_emerge/Scheduler.py b/pym/_emerge/Scheduler.py
index 14b89a8..ee53d0d 100644
--- a/pym/_emerge/Scheduler.py
+++ b/pym/_emerge/Scheduler.py
@@ -96,7 +96,7 @@ class Scheduler(PollScheduler):
 		__slots__ = ("log_file", "schedule")
 
 	_task_queues_class = slot_dict_class(
-		("merge", "jobs", "fetch", "unpack"), prefix="")
+		("merge", "jobs", "ebuild_locks", "fetch", "unpack"), prefix="")
 
 	class _build_opts_class(SlotObject):
 		__slots__ = ("buildpkg", "buildpkgonly",
@@ -389,6 +389,8 @@ class Scheduler(PollScheduler):
 	def _set_max_jobs(self, max_jobs):
 		self._max_jobs = max_jobs
 		self._task_queues.jobs.max_jobs = max_jobs
+		if "parallel-install" in self.settings.features:
+			self._task_queues.merge.max_jobs = max_jobs
 
 	def _background_mode(self):
 		"""
@@ -565,7 +567,16 @@ class Scheduler(PollScheduler):
 		Schedule a setup phase on the merge queue, in order to
 		serialize unsandboxed access to the live filesystem.
 		"""
-		self._task_queues.merge.add(setup_phase)
+		if self._task_queues.merge.max_jobs > 1 and \
+			"ebuild-locks" in self.settings.features:
+			# Use a separate queue for ebuild-locks when the merge
+			# queue allows more than 1 job (due to parallel-install),
+			# since the portage.locks module does not behave as desired
+			# if we try to lock the same file multiple times
+			# concurrently from the same process.
+			self._task_queues.ebuild_locks.add(setup_phase)
+		else:
+			self._task_queues.merge.add(setup_phase)
 		self._schedule()
 
 	def _schedule_unpack(self, unpack_phase):
diff --git a/pym/_emerge/main.py b/pym/_emerge/main.py
index 29cac4b..0a1f337 100644
--- a/pym/_emerge/main.py
+++ b/pym/_emerge/main.py
@@ -356,7 +356,8 @@ def post_emerge(myaction, myopts, myfiles,
 	portage.util.ensure_dirs(vdb_path)
 	vdb_lock = None
 	if os.access(vdb_path, os.W_OK) and not "--pretend" in myopts:
-		vdb_lock = portage.locks.lockdir(vdb_path)
+		vardbapi.lock()
+		vdb_lock = True
 
 	if vdb_lock:
 		try:
@@ -366,7 +367,7 @@ def post_emerge(myaction, myopts, myfiles,
 			mtimedb.commit()
 		finally:
 			if vdb_lock:
-				portage.locks.unlockdir(vdb_lock)
+				vardbapi.unlock()
 
 	chk_updated_cfg_files(settings['EROOT'], config_protect)
 
diff --git a/pym/_emerge/unmerge.py b/pym/_emerge/unmerge.py
index 8fff516..5331744 100644
--- a/pym/_emerge/unmerge.py
+++ b/pym/_emerge/unmerge.py
@@ -11,6 +11,7 @@ from portage import os
 from portage.dbapi._expand_new_virt import expand_new_virt
 from portage.output import bold, colorize, darkgreen, green
 from portage._sets import SETPREFIX
+from portage._sets.base import EditablePackageSet
 from portage.util import cmp_sort_key
 
 from _emerge.emergelog import emergelog
@@ -57,7 +58,8 @@ def unmerge(root_config, myopts, unmerge_action,
 	vdb_lock = None
 	try:
 		if os.access(vdb_path, os.W_OK):
-			vdb_lock = portage.locks.lockdir(vdb_path)
+			vartree.dbapi.lock()
+			vdb_lock = True
 
 		realsyslist = []
 		for x in sets["system"].getAtoms():
@@ -293,10 +295,8 @@ def unmerge(root_config, myopts, unmerge_action,
 	finally:
 		if vdb_lock:
 			vartree.dbapi.flush_cache()
-			portage.locks.unlockdir(vdb_lock)
-	
-	from portage._sets.base import EditablePackageSet
-	
+			vartree.dbapi.unlock()
+
 	# generate a list of package sets that are directly or indirectly listed in "selected",
 	# as there is no persistent list of "installed" sets
 	installed_sets = ["selected"]
diff --git a/pym/portage/const.py b/pym/portage/const.py
index 6b7b05b..ed8a460 100644
--- a/pym/portage/const.py
+++ b/pym/portage/const.py
@@ -88,12 +88,13 @@ EBUILD_PHASES            = ("pretend", "setup", "unpack", "prepare", "configure"
 SUPPORTED_FEATURES       = frozenset([
                            "assume-digests", "binpkg-logs", "buildpkg", "buildsyspkg", "candy",
                            "ccache", "chflags", "collision-protect", "compress-build-logs",
-                           "digest", "distcc", "distlocks", "fakeroot",
+                           "digest", "distcc", "distlocks", "ebuild-locks", "fakeroot",
                            "fail-clean", "fixpackages", "force-mirror", "getbinpkg",
                            "installsources", "keeptemp", "keepwork", "fixlafiles", "lmirror",
                            "metadata-transfer", "mirror", "multilib-strict", "news",
-                           "noauto", "noclean", "nodoc", "noinfo", "noman", "nostrip",
-                           "notitles", "parallel-fetch", "parse-eapi-ebuild-head",
+                           "noauto", "noclean", "nodoc", "noinfo", "noman",
+                           "nostrip", "notitles", "parallel-fetch", "parallel-install",
+                           "parse-eapi-ebuild-head",
                            "prelink-checksums", "preserve-libs",
                            "protect-owned", "python-trace", "sandbox",
                            "selinux", "sesandbox", "severe", "sfperms",
diff --git a/pym/portage/dbapi/vartree.py b/pym/portage/dbapi/vartree.py
index be7d58c..f1dcb45 100644
--- a/pym/portage/dbapi/vartree.py
+++ b/pym/portage/dbapi/vartree.py
@@ -15,7 +15,7 @@ portage.proxy.lazyimport.lazyimport(globals(),
 	 	'use_reduce,_slot_re',
 	'portage.elog:collect_ebuild_messages,collect_messages,' + \
 		'elog_process,_merge_logentries',
-	'portage.locks:lockdir,unlockdir',
+	'portage.locks:lockdir,unlockdir,lockfile,unlockfile',
 	'portage.output:bold,colorize',
 	'portage.package.ebuild.doebuild:doebuild_environment,' + \
 		'_spawn_phase',
@@ -139,6 +139,10 @@ class vardbapi(dbapi):
 		self._lock = None
 		self._lock_count = 0
 
+		self._conf_mem_file = self._eroot + CONFIG_MEMORY_FILE
+		self._fs_lock_obj = None
+		self._fs_lock_count = 0
+
 		if vartree is None:
 			vartree = portage.db[self.root]["vartree"]
 		self.vartree = vartree
@@ -209,6 +213,28 @@ class vardbapi(dbapi):
 			unlockdir(self._lock)
 			self._lock = None
 
+	def _fs_lock(self):
+		"""
+		Acquire a reentrant lock, blocking, for cooperation with concurrent
+		processes.
+		"""
+		if self._fs_lock_count < 1:
+			if self._fs_lock_obj is not None:
+				raise AssertionError("already locked")
+			self._fs_lock_obj = lockfile(self._conf_mem_file)
+		self._fs_lock_count += 1
+
+	def _fs_unlock(self):
+		"""
+		Release a lock, decrementing the recursion level.
+		"""
+		if self._fs_lock_count <= 1:
+			if self._fs_lock_obj is None:
+				raise AssertionError("not locked")
+			unlockfile(self._fs_lock_obj)
+			self._fs_lock_obj = None
+		self._fs_lock_count -= 1
+
 	def _bump_mtime(self, cpv):
 		"""
 		This is called before an after any modifications, so that consumers
@@ -791,16 +817,15 @@ class vardbapi(dbapi):
 		self.lock()
 		try:
 			counter = self.get_counter_tick_core() - 1
-			if self._cached_counter != counter:
-				if incrementing:
-					#increment counter
-					counter += 1
-					# use same permissions as config._init_dirs()
-					ensure_dirs(os.path.dirname(self._counter_path),
-						gid=portage_gid, mode=0o2750, mask=0o2)
-					# update new global counter file
-					write_atomic(self._counter_path, str(counter))
-				self._cached_counter = counter
+			if incrementing:
+				#increment counter
+				counter += 1
+				# use same permissions as config._init_dirs()
+				ensure_dirs(os.path.dirname(self._counter_path),
+					gid=portage_gid, mode=0o2750, mask=0o2)
+				# update new global counter file
+				write_atomic(self._counter_path, str(counter))
+			self._cached_counter = counter
 		finally:
 			self.unlock()
 
@@ -1276,6 +1301,7 @@ class dblink(object):
 		self.dbpkgdir = self.dbcatdir+"/"+pkg
 		self.dbtmpdir = self.dbcatdir+"/-MERGING-"+pkg
 		self.dbdir = self.dbpkgdir
+
 		self.settings = mysettings
 		self._verbose = self.settings.get("PORTAGE_VERBOSE") == "1"
 
@@ -1353,8 +1379,12 @@ class dblink(object):
 		"""
 		For a given db entry (self), erase the CONTENTS values.
 		"""
-		if os.path.exists(self.dbdir+"/CONTENTS"):
-			os.unlink(self.dbdir+"/CONTENTS")
+		self.lockdb()
+		try:
+			if os.path.exists(self.dbdir+"/CONTENTS"):
+				os.unlink(self.dbdir+"/CONTENTS")
+		finally:
+			self.unlockdb()
 
 	def _clear_contents_cache(self):
 		self.contentscache = None
@@ -1469,6 +1499,7 @@ class dblink(object):
 		# remove preserved libraries that don't have any consumers left
 		plib_registry = self.vartree.dbapi._plib_registry
 		if plib_registry:
+			self.vartree.dbapi._fs_lock()
 			plib_registry.lock()
 			try:
 				plib_registry.load()
@@ -1498,6 +1529,7 @@ class dblink(object):
 				plib_registry.store()
 			finally:
 				plib_registry.unlock()
+				self.vartree.dbapi._fs_unlock()
 
 	def unmerge(self, pkgfiles=None, trimworld=None, cleanup=True,
 		ldpath_mtimes=None, others_in_slot=None, needed=None,
@@ -1530,10 +1562,6 @@ class dblink(object):
 		@returns:
 		1. os.EX_OK if everything went well.
 		2. return code of the failed phase (for prerm, postrm, cleanrm)
-		
-		Notes:
-		The caller must ensure that lockdb() and unlockdb() are called
-		before and after this method.
 		"""
 
 		if trimworld is not None:
@@ -1636,7 +1664,11 @@ class dblink(object):
 					showMessage(_("!!! FAILED prerm: %s\n") % retval,
 						level=logging.ERROR, noiselevel=-1)
 
-			self._unmerge_pkgfiles(pkgfiles, others_in_slot)
+			self.vartree.dbapi._fs_lock()
+			try:
+				self._unmerge_pkgfiles(pkgfiles, others_in_slot)
+			finally:
+				self.vartree.dbapi._fs_unlock()
 			self._clear_contents_cache()
 
 			if myebuildpath:
@@ -1746,10 +1778,17 @@ class dblink(object):
 		else:
 			self.settings.pop("PORTAGE_LOG_FILE", None)
 
-		env_update(target_root=self.settings['ROOT'],
-			prev_mtimes=ldpath_mtimes,
-			contents=contents, env=self.settings.environ(),
-			writemsg_level=self._display_merge)
+		# Lock the config memory file to prevent symlink creation
+		# in merge_contents from overlapping with env-update.
+		self.vartree.dbapi._fs_lock()
+		try:
+			env_update(target_root=self.settings['ROOT'],
+				prev_mtimes=ldpath_mtimes,
+				contents=contents, env=self.settings.environ(),
+				writemsg_level=self._display_merge)
+		finally:
+			self.vartree.dbapi._fs_unlock()
+
 		return os.EX_OK
 
 	def _display_merge(self, msg, level=0, noiselevel=0):
@@ -1804,8 +1843,7 @@ class dblink(object):
 		dest_root = self._eroot
 		dest_root_len = len(dest_root) - 1
 
-		conf_mem_file = os.path.join(dest_root, CONFIG_MEMORY_FILE)
-		cfgfiledict = grabdict(conf_mem_file)
+		cfgfiledict = grabdict(self.vartree.dbapi._conf_mem_file)
 		stale_confmem = []
 
 		unmerge_orphans = "unmerge-orphans" in self.settings.features
@@ -2055,7 +2093,7 @@ class dblink(object):
 		if stale_confmem:
 			for filename in stale_confmem:
 				del cfgfiledict[filename]
-			writedict(cfgfiledict, conf_mem_file)
+			writedict(cfgfiledict, self.vartree.dbapi._conf_mem_file)
 
 		#remove self from vartree database so that our own virtual gets zapped if we're the last node
 		self.vartree.zap(self.mycpv)
@@ -3182,8 +3220,12 @@ class dblink(object):
 					# get_owners is slow for large numbers of files, so
 					# don't look them all up.
 					collisions = collisions[:20]
-				owners = self.vartree.dbapi._owners.get_owners(collisions)
-				self.vartree.dbapi.flush_cache()
+				self.lockdb()
+				try:
+					owners = self.vartree.dbapi._owners.get_owners(collisions)
+					self.vartree.dbapi.flush_cache()
+				finally:
+					self.unlockdb()
 
 				for pkg, owned_files in owners.items():
 					cpv = pkg.mycpv
@@ -3262,26 +3304,28 @@ class dblink(object):
 		self.updateprotect()
 
 		#if we have a file containing previously-merged config file md5sums, grab it.
-		conf_mem_file = os.path.join(self._eroot, CONFIG_MEMORY_FILE)
-		cfgfiledict = grabdict(conf_mem_file)
-		if "NOCONFMEM" in self.settings:
-			cfgfiledict["IGNORE"]=1
-		else:
-			cfgfiledict["IGNORE"]=0
-
-		# Always behave like --noconfmem is enabled for downgrades
-		# so that people who don't know about this option are less
-		# likely to get confused when doing upgrade/downgrade cycles.
-		pv_split = catpkgsplit(self.mycpv)[1:]
-		for other in others_in_slot:
-			if pkgcmp(pv_split, catpkgsplit(other.mycpv)[1:]) < 0:
-				cfgfiledict["IGNORE"] = 1
-				break
+		self.vartree.dbapi._fs_lock()
+		try:
+			cfgfiledict = grabdict(self.vartree.dbapi._conf_mem_file)
+			if "NOCONFMEM" in self.settings:
+				cfgfiledict["IGNORE"]=1
+			else:
+				cfgfiledict["IGNORE"]=0
+
+			# Always behave like --noconfmem is enabled for downgrades
+			# so that people who don't know about this option are less
+			# likely to get confused when doing upgrade/downgrade cycles.
+			pv_split = catpkgsplit(self.mycpv)[1:]
+			for other in others_in_slot:
+				if pkgcmp(pv_split, catpkgsplit(other.mycpv)[1:]) < 0:
+					cfgfiledict["IGNORE"] = 1
+					break
 
-		rval = self._merge_contents(srcroot, destroot, cfgfiledict,
-			conf_mem_file)
-		if rval != os.EX_OK:
-			return rval
+			rval = self._merge_contents(srcroot, destroot, cfgfiledict)
+			if rval != os.EX_OK:
+				return rval
+		finally:
+			self.vartree.dbapi._fs_unlock()
 
 		# These caches are populated during collision-protect and the data
 		# they contain is now invalid. It's very important to invalidate
@@ -3298,6 +3342,7 @@ class dblink(object):
 		preserve_paths = None
 		needed = None
 		if not (linkmap is None or plib_registry is None):
+			self.vartree.dbapi._fs_lock()
 			plib_registry.lock()
 			try:
 				plib_registry.load()
@@ -3308,6 +3353,7 @@ class dblink(object):
 				preserve_paths = self._find_libs_to_preserve()
 			finally:
 				plib_registry.unlock()
+				self.vartree.dbapi._fs_unlock()
 
 			if preserve_paths:
 				self._add_preserve_libs_to_contents(preserve_paths)
@@ -3353,8 +3399,12 @@ class dblink(object):
 			else:
 				emerge_log(_(" !!! unmerge FAILURE: %s") % (dblnk.mycpv,))
 
-			# TODO: Check status and abort if necessary.
-			dblnk.delete()
+			self.lockdb()
+			try:
+				# TODO: Check status and abort if necessary.
+				dblnk.delete()
+			finally:
+				self.unlockdb()
 			showMessage(_(">>> Original instance of package unmerged safely.\n"))
 
 		if len(others_in_slot) > 1:
@@ -3365,8 +3415,12 @@ class dblink(object):
 
 		# We hold both directory locks.
 		self.dbdir = self.dbpkgdir
-		self.delete()
-		_movefile(self.dbtmpdir, self.dbpkgdir, mysettings=self.settings)
+		self.lockdb()
+		try:
+			self.delete()
+			_movefile(self.dbtmpdir, self.dbpkgdir, mysettings=self.settings)
+		finally:
+			self.unlockdb()
 
 		# Check for file collisions with blocking packages
 		# and remove any colliding files from their CONTENTS
@@ -3374,12 +3428,17 @@ class dblink(object):
 		self._clear_contents_cache()
 		contents = self.getcontents()
 		destroot_len = len(destroot) - 1
-		for blocker in blockers:
-			self.vartree.dbapi.removeFromContents(blocker, iter(contents),
-				relative_paths=False)
+		self.lockdb()
+		try:
+			for blocker in blockers:
+				self.vartree.dbapi.removeFromContents(blocker, iter(contents),
+					relative_paths=False)
+		finally:
+			self.unlockdb()
 
 		plib_registry = self.vartree.dbapi._plib_registry
 		if plib_registry:
+			self.vartree.dbapi._fs_lock()
 			plib_registry.lock()
 			try:
 				plib_registry.load()
@@ -3409,6 +3468,7 @@ class dblink(object):
 				plib_registry.store()
 			finally:
 				plib_registry.unlock()
+				self.vartree.dbapi._fs_unlock()
 
 		self.vartree.dbapi._add(self)
 		contents = self.getcontents()
@@ -3439,11 +3499,17 @@ class dblink(object):
 			if pkgcmp(catpkgsplit(self.pkg)[1:], catpkgsplit(v)[1:]) < 0:
 				downgrade = True
 
-		#update environment settings, library paths. DO NOT change symlinks.
-		env_update(makelinks=(not downgrade),
-			target_root=self.settings['ROOT'], prev_mtimes=prev_mtimes,
-			contents=contents, env=self.settings.environ(),
-			writemsg_level=self._display_merge)
+		# Lock the config memory file to prevent symlink creation
+		# in merge_contents from overlapping with env-update.
+		self.vartree.dbapi._fs_lock()
+		try:
+			#update environment settings, library paths. DO NOT change symlinks.
+			env_update(makelinks=(not downgrade),
+				target_root=self.settings['ROOT'], prev_mtimes=prev_mtimes,
+				contents=contents, env=self.settings.environ(),
+				writemsg_level=self._display_merge)
+		finally:
+			self.vartree.dbapi._fs_unlock()
 
 		# For gcc upgrades, preserved libs have to be removed after the
 		# the library path has been updated.
@@ -3471,7 +3537,7 @@ class dblink(object):
 
 		return backup_p
 
-	def _merge_contents(self, srcroot, destroot, cfgfiledict, conf_mem_file):
+	def _merge_contents(self, srcroot, destroot, cfgfiledict):
 
 		cfgfiledict_orig = cfgfiledict.copy()
 
@@ -3533,9 +3599,9 @@ class dblink(object):
 		# write out our collection of md5sums
 		if cfgfiledict != cfgfiledict_orig:
 			cfgfiledict.pop("IGNORE", None)
-			ensure_dirs(os.path.dirname(conf_mem_file),
+			ensure_dirs(os.path.dirname(self.vartree.dbapi._conf_mem_file),
 				gid=portage_gid, mode=0o2750, mask=0o2)
-			writedict(cfgfiledict, conf_mem_file)
+			writedict(cfgfiledict, self.vartree.dbapi._conf_mem_file)
 
 		return os.EX_OK
 
@@ -3866,7 +3932,9 @@ class dblink(object):
 		"""
 		myroot = None
 		retval = -1
-		self.lockdb()
+		parallel_install = "parallel-install" in self.settings.features
+		if not parallel_install:
+			self.lockdb()
 		self.vartree.dbapi._bump_mtime(self.mycpv)
 		try:
 			retval = self.treewalk(mergeroot, myroot, inforoot, myebuild,
@@ -3919,8 +3987,9 @@ class dblink(object):
 				pass
 			else:
 				self.vartree.dbapi._linkmap._clear_cache()
-			self.unlockdb()
 			self.vartree.dbapi._bump_mtime(self.mycpv)
+			if not parallel_install:
+				self.unlockdb()
 		return retval
 
 	def getstring(self,name):
@@ -4021,12 +4090,18 @@ def unmerge(cat, pkg, myroot=None, settings=None,
 	mylink = dblink(cat, pkg, settings=settings, treetype="vartree",
 		vartree=vartree, scheduler=scheduler)
 	vartree = mylink.vartree
-	mylink.lockdb()
+	parallel_install = "parallel-install" in settings.features
+	if not parallel_install:
+		mylink.lockdb()
 	try:
 		if mylink.exists():
 			retval = mylink.unmerge(ldpath_mtimes=ldpath_mtimes)
 			if retval == os.EX_OK:
-				mylink.delete()
+				mylink.lockdb()
+				try:
+					mylink.delete()
+				finally:
+					mylink.unlockdb()
 			return retval
 		return os.EX_OK
 	finally:
@@ -4035,7 +4110,8 @@ def unmerge(cat, pkg, myroot=None, settings=None,
 			pass
 		else:
 			vartree.dbapi._linkmap._clear_cache()
-		mylink.unlockdb()
+		if not parallel_install:
+			mylink.unlockdb()
 
 def write_contents(contents, root, f):
 	"""
diff --git a/pym/portage/util/_dyn_libs/LinkageMapELF.py b/pym/portage/util/_dyn_libs/LinkageMapELF.py
index 3305aca..fe86a7a 100644
--- a/pym/portage/util/_dyn_libs/LinkageMapELF.py
+++ b/pym/portage/util/_dyn_libs/LinkageMapELF.py
@@ -181,15 +181,20 @@ class LinkageMapELF(object):
 				lines.append((include_file, line))
 
 		aux_keys = [self._needed_aux_key]
-		for cpv in self._dbapi.cpv_all():
-			if exclude_pkgs is not None and cpv in exclude_pkgs:
-				continue
-			needed_file = self._dbapi.getpath(cpv,
-				filename=self._needed_aux_key)
-			for line in self._dbapi.aux_get(cpv, aux_keys)[0].splitlines():
-				lines.append((needed_file, line))
-		# Cache NEEDED.* files avoid doing excessive IO for every rebuild.
-		self._dbapi.flush_cache()
+		can_lock = os.access(os.path.dirname(self._dbapi._dbroot), os.W_OK)
+		if can_lock:
+			self._dbapi.lock()
+		try:
+			for cpv in self._dbapi.cpv_all():
+				if exclude_pkgs is not None and cpv in exclude_pkgs:
+					continue
+				needed_file = self._dbapi.getpath(cpv,
+					filename=self._needed_aux_key)
+				for line in self._dbapi.aux_get(cpv, aux_keys)[0].splitlines():
+					lines.append((needed_file, line))
+		finally:
+			if can_lock:
+				self._dbapi.unlock()
 
 		# have to call scanelf for preserved libs here as they aren't 
 		# registered in NEEDED.ELF.2 files
diff --git a/pym/portage/util/movefile.py b/pym/portage/util/movefile.py
index f8cc695..e07e8ca 100644
--- a/pym/portage/util/movefile.py
+++ b/pym/portage/util/movefile.py
@@ -90,7 +90,8 @@ def movefile(src, dest, newmtime=None, sstat=None, mysettings=None,
 				# to tolerate these links being recreated during the merge
 				# process. In any case, if the link is pointing at the right
 				# place, we're in good shape.
-				if e.errno != errno.ENOENT or target != os.readlink(dest):
+				if e.errno not in (errno.ENOENT, errno.EEXIST) or \
+					target != os.readlink(dest):
 					raise
 			lchown(dest,sstat[stat.ST_UID],sstat[stat.ST_GID])
 			# utime() only works on the target of a symlink, so it's not
