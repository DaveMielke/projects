From 0f55425cfb5d78fdc86ea248d1ef7fbe2ed2c376 Mon Sep 17 00:00:00 2001
From: Brian Harring <ferringb@chromium.org>
Date: Mon, 3 Oct 2011 16:06:46 -0700
Subject: [PATCH] Squashed commit of the following:

commit 261eb4fc7176f311c1095b481c78e1bbcedb9770
Author: Zac Medico <zmedico@gentoo.org>
Date:   Fri Sep 30 12:08:31 2011 -0700

    Fix 'authoritative' spelling.
    (cherry picked from commit ed3b2b43aa329d007f7bb0eb303b3f74e927970a)

commit 751255d4f19ad5f271397f2e7cdfdc36d0127f85
Author: Brian Harring <ferringb@chromium.org>
Date:   Fri Sep 30 02:37:04 2011 -0700

    layout.conf: allow a repository to state the cache is authorative

    By authorative, this means "the cache is accurate; skip validation".  While
    a useful hint for a slight speedup in validation, the true gain is for
    repositories that are distributed in a fashion that doesn't preserve mtime;
    git primarily.  Setting authorative-cache = true results in portage
    skipping mtime validation checks for the bundled cache, allowing
    for git vcs based repos to distribute a cache.

    BUG=chromium-os:21049
    TEST=dump a cache into metadata/cache, touch it to now, set layout.conf
         to authorative-cache=true, verify it doesn't generate cache entries
         for that repo.

    Change-Id: I92423e679bc171d2411a18d6d3ac22e8ef457753
    (cherry picked from commit a72a01746638debe472496bd8fc661992a6ba08b)

commit bd0bd95dd95e330374c915dd3c80e228c093aeea
Author: Brian Harring <ferringb@chromium.org>
Date:   Fri Sep 23 16:43:28 2011 -0700

    manifest: controllable per repo

    This adds three states to layout.conf key use-manifest; false, true, and strict.

    false means "don't use manifests at all"
    true means "use and generate manifests, but allow them to be missing"
    strict means "manifests must be used everywhere in this repo"

    BUG=chromium-os:11308
    TEST=repoman manifest usage.

    Change-Id: Ie5c40480a4763592cafd206408fc8125d5f70cf8
    Reviewed-on: http://gerrit.chromium.org/gerrit/8317
    Reviewed-by: Zac Medico <zmedico@gmail.com>
    Tested-by: Zac Medico <zmedico@gmail.com>
    Reviewed-by: David James <davidjames@chromium.org>
    Tested-by: Brian Harring <ferringb@chromium.org>
    Reviewed-by: Brian Harring <ferringb@chromium.org>

commit 788c5f5960dedde228f69ee67bb98d46fed5f7d6
Author: Brian Harring <ferringb@gmail.com>
Date:   Wed Sep 21 15:50:28 2011 -0700

    add install hooks

    For cros, either we have to jam our custom copyright/license analysis
    into portage (undesirable), or add hook infrastructure.  Thus we
    add hook infrastructure.

    BUG=chromium-os:14863
    TEST=add a script to etc/portage/hooks/install that outputs something,
         ensure it outputs.

    This is a squashing of 2 cherry-picks (latter being just a typo fix):
    (cherry picked from commit 9144182d9c8f0cf16973d8ec91eafc624310c6ca)
    (cherry picked from commit ed9982d781a81651db0480af128a6509eafe358a)

commit e09e7570a86a29eac22696a1f1f4d36571ac98d9
Author: Zac Medico <zmedico@gentoo.org>
Date:   Mon Sep 12 23:06:50 2011 -0700

    man/portage.5: layout.conf examples manifests
    (cherry picked from commit 68462daca775701f090cf9fc442310512c585e6b)

commit 4f46ce6911e5e394263ac869dfef011a8c3dc6e9
Author: Zac Medico <zmedico@gentoo.org>
Date:   Wed Sep 14 19:36:54 2011 -0700

    Remove Manifest if it is not needed.

    With thin manifest, there's no need to have a Manifest file if there
    are no DIST entries.
    (cherry picked from commit 7a216218968dc1d00f2881121870611bc1b5dd33)

commit 11700d378c62af823347ce92271bc2419d9fa8e1
Author: Zac Medico <zmedico@gentoo.org>
Date:   Mon Sep 12 21:33:01 2011 -0700

    doebuild: support allow-missing and thin manifest
    (cherry picked from commit 48a2edbf0f0677cc97bae388cc391b563c8e4859)

commit 5f50fbd62f37dde39c1888321f5f62a534bfc127
Author: David James <davidjames@chromium.org>
Date:   Mon Aug 22 16:29:13 2011 -0700

    Update --rebuild-if-* flags to rebuild when build dependencies are changed.

    Right now, the --rebuild-if-* flags only rebuild packages that are used at
    both run-time and build-time. This doesn't help for packages that are used
    only at build-time (for example, static libaries).

    Rebuilding packages whenever a build-time dependency is changed is easier to
    understand and explain, and it handles all cases correctly.

    BUG=chromium-os:15517
    TEST=Run emerge test suite.

    Change-Id: Iae8dab24e8acb6625bc1a0ce41862e90b232eb84

commit 37727140938ca9137564813b8f965989a097e97e
Author: David James <davidjames@google.com>
Date:   Tue Sep 13 14:46:42 2011 -0700

    Commit fast-build patch to portage_tool repository.

    This patch allows us to selectively disable Portage locks in parallel_emerge.
    It is not intended to be upstreamed but is left in for now until we find a way
    to replace it (e.g. by integrating parallel emerge support directly into portage
    itself).

    Note- imported directly from patch, original metadata/sha1 lost

    Change-Id: I4ea50e206102b249ba01d2f760ebaba221bddd18

    BUG=chromium-os:11324
    TEST=build_packages --nousepkg

    Review URL: http://codereview.chromium.org/6377009

commit 757be2ff983e791a42f334ce11787650ca91c198
Author: David James <davidjames@google.com>
Date:   Thu Sep 15 15:49:31 2011 -0700

    Update Portage to support fixing *.la and *.pc files, support suppressing env-update

    *.la and *.pc files need to be fixed up in order to ensure packages link
    against the right library when we try to build / install to different ROOTs.

    BUG=chromium-os:11316
    TEST=Compile with build_packages --nousepkg

    Review URL: http://codereview.chromium.org/6370011
    Change-Id: I99db793c3c0dc3fab7646a7fbb258fdc40b086a9

commit 066970aba04c2511e820e1180c098e2ccaf9d5b4
Author: Zac Medico <zmedico@gentoo.org>
Date:   Sun Sep 18 16:45:20 2011 -0700

    env_update: add more vardbapi fallback code

    For API consumers that call this function without the vardbapi
    parameter, it whould continue to work correctly in all the cases
    that worked before the vardbapi was added.
    (cherry picked from commit 89664c0c4280372be5b593880c2ac5ccc695f688)

commit 6e77ee638da6af20c0fec2d9b4b751587d87938e
Author: Zac Medico <zmedico@gentoo.org>
Date:   Sun Sep 18 15:47:45 2011 -0700

    env_update: use global vardbapi as fallback
    (cherry picked from commit 1a5a662780f7a4401a89f0939a9180872f36f05f)

commit 4ccd287ebfb17bc816410ac3d2af9da4673672d0
Author: Brian Harring <ferringb@chromium.org>
Date:   Thu Sep 15 15:06:44 2011 -0700

    move locking into env_update itself
    (cherry picked from commit a0aaafd899a684a2ce06db1f019513b2cb28fa63)

commit 0c34593c56683bfd7d73d5308a892db29a51a8b2
Author: Zac Medico <zmedico@gentoo.org>
Date:   Wed Sep 14 22:30:46 2011 -0700

    digestcheck: only show relevant msgs for thin
    (cherry picked from commit 01d4dde5a17648b8004e3633bf11ed945a0fa796)

commit 81468457dac2ad2c2c2536d46b1ef8b46998837f
Author: Zac Medico <zmedico@gentoo.org>
Date:   Wed Sep 14 19:44:28 2011 -0700

    digestcheck: remove empty/missing Manifest checks

    These checks never really needed, and they are not valid for thin
    manifests or allow-missing-manifests.
    (cherry picked from commit 7b9709d96425606366b56b33168544a6897d69b0)

commit 6060f3c23dc9e24a61c3c54ebba066cfeac94464
Author: Zac Medico <zmedico@gentoo.org>
Date:   Wed Sep 14 19:21:45 2011 -0700

    Don't write empty (thin) Manifest files.

    With thin manifest, there's no need to have a Manifest file if there
    are no DIST entries.
    (cherry picked from commit d1f3fdfb943a9021d454c12b3418e44e5275ad69)

commit 96b6b80f7a6279de9b309afe0886f381b59f62c6
Author: Brian Harring <ferringb@gmail.com>
Date:   Thu Sep 1 14:50:25 2011 -0700

    add layout.conf awareness of thin-manifests

    For any repo that wants thin (just src_uri digests), they just need to add

    thin-manifests = true

    to their layout.conf.  Again, this should only be used in repositories
    were the backing vcs provides checksums for the ebuild data.
    (cherry picked from commit af7933ee4df1d62a6567510dc7e84a0cf13a09ef)

commit 7177b75c86820ca0c41c8f09a77e59826759ba91
Author: Brian Harring <ferringb@gmail.com>
Date:   Thu Sep 1 14:36:45 2011 -0700

    add thin manifest support to the Manifest class

    'thin' is just distfiles.  This is primarily useful when the ebuild
    lives in a vcs- git for example, which already has it's own checksums
    to rely on.
    (cherry picked from commit 69613e420d5be52e413c7c60e571710c2597f58d)

commit 0ba4accc2129a1cb9cd5b667b32b343415239f1a
Author: Brian Harring <ferringb@gmail.com>
Date:   Wed Aug 31 17:29:58 2011 -0700

    Bind all manifest access through repoconfigs

    This enables controling the behaviour (creation and validation) per
    repo, and while mildly ugly, refactors in the right direction.
    (cherry picked from commit f908cddb505b81533861196c4713378e63dac1fa)

    Conflicts:

    	pym/_emerge/search.py

commit 5dd8480595c77a25b4d79e63171267460d655cff
Author: Brian Harring <ferringb@gmail.com>
Date:   Wed Aug 31 16:42:34 2011 -0700

    refactoring; unhide part of the parsing functionality
    (cherry picked from commit 53860ffa675b0cf1930589ff9fa15b5ffaa2cf75)
---
 bin/ebuild                                 |    5 +-
 bin/misc-functions.sh                      |   15 ++
 bin/repoman                                |    8 +-
 man/emerge.1                               |   14 +-
 man/make.conf.5                            |    4 -
 man/portage.5                              |    7 +
 pym/_emerge/EbuildFetcher.py               |   19 ++-
 pym/_emerge/depgraph.py                    |  150 ++++++++-----------
 pym/_emerge/help.py                        |   18 +--
 pym/_emerge/search.py                      |    5 +-
 pym/portage/cache/template.py              |    1 +
 pym/portage/const.py                       |    5 +-
 pym/portage/dbapi/porttree.py              |   23 ++-
 pym/portage/dbapi/vartree.py               |   48 +++---
 pym/portage/manifest.py                    |  173 ++++++++++++++-------
 pym/portage/package/ebuild/digestcheck.py  |   50 ++----
 pym/portage/package/ebuild/digestgen.py    |    9 +-
 pym/portage/package/ebuild/doebuild.py     |   56 +++++---
 pym/portage/package/ebuild/fetch.py        |    3 +-
 pym/portage/repository/config.py           |  227 +++++++++++++++------------
 pym/portage/tests/resolver/test_rebuild.py |   65 +++++----
 pym/portage/util/env_update.py             |   39 +++++-
 22 files changed, 544 insertions(+), 400 deletions(-)

diff --git a/bin/ebuild b/bin/ebuild
index f8b6d79..3f49f70 100755
--- a/bin/ebuild
+++ b/bin/ebuild
@@ -204,8 +204,9 @@ def discard_digests(myebuild, mysettings, mydbapi):
 		portage._doebuild_manifest_exempt_depend += 1
 		pkgdir = os.path.dirname(myebuild)
 		fetchlist_dict = portage.FetchlistDict(pkgdir, mysettings, mydbapi)
-		from portage.manifest import Manifest
-		mf = Manifest(pkgdir, mysettings["DISTDIR"],
+		mf = mysettings.repositories.get_repo_for_location(
+			os.path.dirname(os.path.dirname(pkgdir)))
+		mf = mf.load_manifest(pkgdir, mysettings["DISTDIR"],
 			fetchlist_dict=fetchlist_dict, manifest1_compat=False)
 		mf.create(requiredDistfiles=None,
 			assumeDistHashesSometimes=True, assumeDistHashesAlways=True)
diff --git a/bin/misc-functions.sh b/bin/misc-functions.sh
index 8c191ff..4dae41d 100755
--- a/bin/misc-functions.sh
+++ b/bin/misc-functions.sh
@@ -985,6 +985,21 @@ success_hooks() {
 	done
 }
 
+install_hooks() {
+	local hooks_dir="${PORTAGE_CONFIGROOT}etc/portage/hooks/install"
+	local fp
+	local ret=0
+	shopt -s nullglob
+	for fp in "${hooks_dir}"/*; do
+		if [ -x "$fp" ]; then
+			"$fp"
+			ret=$(( $ret | $? ))
+		fi
+	done
+	shopt +s nullglob
+	return $ret
+}
+
 if [ -n "${MISC_FUNCTIONS_ARGS}" ]; then
 	source_all_bashrcs
 	[ "$PORTAGE_DEBUG" == "1" ] && set -x
diff --git a/bin/repoman b/bin/repoman
index 10f603e..a90729c 100755
--- a/bin/repoman
+++ b/bin/repoman
@@ -1103,7 +1103,9 @@ for x in scanlist:
 			portage._doebuild_manifest_exempt_depend += 1
 			try:
 				distdir = repoman_settings['DISTDIR']
-				mf = portage.manifest.Manifest(checkdir, distdir,
+				mf = repoman_settings.repositories.get_repo_for_location(
+					os.path.dirname(os.path.dirname(checkdir)))
+				mf = mf.load_manifest(checkdir, distdir,
 					fetchlist_dict=fetchlist_dict)
 				mf.create(requiredDistfiles=None,
 					assumeDistHashesAlways=True)
@@ -1308,7 +1310,9 @@ for x in scanlist:
 				raise
 			continue
 
-	mf = Manifest(checkdir, repoman_settings["DISTDIR"])
+	mf = repoman_settings.repositories.get_repo_for_location(
+		os.path.dirname(os.path.dirname(checkdir)))
+	mf = mf.load_manifest(checkdir, repoman_settings["DISTDIR"])
 	mydigests=mf.getTypeDigests("DIST")
 
 	fetchlist_dict = portage.FetchlistDict(checkdir, repoman_settings, portdb)
diff --git a/man/emerge.1 b/man/emerge.1
index 835d2c0..e1df6d2 100644
--- a/man/emerge.1
+++ b/man/emerge.1
@@ -543,18 +543,16 @@ to be set in the \fBmake.conf\fR(5)
 \fBEMERGE_DEFAULT_OPTS\fR variable.
 .TP
 .BR "\-\-rebuild\-if\-new\-rev [ y | n ]"
-Rebuild packages when dependencies that are used at both build\-time and
-run\-time are built, if the dependency is not already installed with the
-same version and revision.
+Rebuild packages when build\-time dependencies are built from source, if the
+dependency is not already installed with the same version and revision.
 .TP
 .BR "\-\-rebuild\-if\-new\-ver [ y | n ]"
-Rebuild packages when dependencies that are used at both build\-time and
-run\-time are built, if the dependency is not already installed with the
-same version. Revision numbers are ignored.
+Rebuild packages when build\-time dependencies are built from source, if the
+dependency is not already installed with the same version. Revision numbers
+are ignored.
 .TP
 .BR "\-\-rebuild\-if\-unbuilt [ y | n ]"
-Rebuild packages when dependencies that are used at both build\-time and
-run\-time are built.
+Rebuild packages when build\-time dependencies are built from source.
 .TP
 .BR "\-\-rebuilt\-binaries [ y | n ]"
 Replace installed packages with binary packages that have
diff --git a/man/make.conf.5 b/man/make.conf.5
index e86dc74..059a6a4 100644
--- a/man/make.conf.5
+++ b/man/make.conf.5
@@ -198,10 +198,6 @@ non-developers as well. The \fBsandbox\fR feature is very important and
 should not be disabled by default.
 .RS
 .TP
-.B allow\-missing\-manifests
-Allow missing manifest entries. This is primarily useful for temporary
-trees or instances where manifests aren't used.
-.TP
 .B assume\-digests
 When commiting work to cvs with \fBrepoman\fR(1), assume that all existing 
 SRC_URI digests are correct.  This feature also affects digest generation via
diff --git a/man/portage.5 b/man/portage.5
index f115570..1f05d97 100644
--- a/man/portage.5
+++ b/man/portage.5
@@ -776,6 +776,13 @@ precedence over settings in \fBlayout.conf\fR, except tools such as
 masters = gentoo java-overlay
 # indicate that this repo can be used as a substitute for foo-overlay
 aliases = foo-overlay
+# do not sign manifests in this repo
+sign\-manifests = false
+# thin\-manifests only contain DIST entries
+thin\-manifests = true
+# indicate that this repo requires manifests for each package, and is
+# considered a failure if a manifest file is missing/incorrect
+use\-manifests = strict
 .fi
 .RE
 .TP
diff --git a/pym/_emerge/EbuildFetcher.py b/pym/_emerge/EbuildFetcher.py
index feb68d0..61c7848 100644
--- a/pym/_emerge/EbuildFetcher.py
+++ b/pym/_emerge/EbuildFetcher.py
@@ -21,7 +21,7 @@ class EbuildFetcher(SpawnProcess):
 
 	__slots__ = ("config_pool", "ebuild_path", "fetchonly", "fetchall",
 		"pkg", "prefetch") + \
-		("_digests", "_settings", "_uri_map")
+		("_digests", "_manifest", "_settings", "_uri_map")
 
 	def already_fetched(self, settings):
 		"""
@@ -40,7 +40,7 @@ class EbuildFetcher(SpawnProcess):
 
 		digests = self._get_digests()
 		distdir = settings["DISTDIR"]
-		allow_missing = "allow-missing-manifests" in settings.features
+		allow_missing = self._get_manifest().allow_missing
 
 		for filename in uri_map:
 			# Use stat rather than lstat since fetch() creates
@@ -179,7 +179,7 @@ class EbuildFetcher(SpawnProcess):
 			not in ('yes', 'true')
 
 		rval = 1
-		allow_missing = 'allow-missing-manifests' in self._settings.features
+		allow_missing = self._get_manifest().allow_missing
 		try:
 			if fetch(self._uri_map, self._settings, fetchonly=self.fetchonly,
 				digests=copy.deepcopy(self._get_digests()),
@@ -203,11 +203,16 @@ class EbuildFetcher(SpawnProcess):
 			raise AssertionError("ebuild not found for '%s'" % self.pkg.cpv)
 		return self.ebuild_path
 
+	def _get_manifest(self):
+		if self._manifest is None:
+			pkgdir = os.path.dirname(self._get_ebuild_path())
+			self._manifest = self.pkg.root_config.settings.repositories.get_repo_for_location(
+				os.path.dirname(os.path.dirname(pkgdir))).load_manifest(pkgdir, None)
+		return self._manifest
+
 	def _get_digests(self):
-		if self._digests is not None:
-			return self._digests
-		self._digests = portage.Manifest(os.path.dirname(
-			self._get_ebuild_path()), None).getTypeDigests("DIST")
+		if self._digests is None:
+			self._digests = self._get_manifest().getTypeDigests("DIST")
 		return self._digests
 
 	def _get_uri_map(self):
diff --git a/pym/_emerge/depgraph.py b/pym/_emerge/depgraph.py
index 8b6125d..42cc659 100644
--- a/pym/_emerge/depgraph.py
+++ b/pym/_emerge/depgraph.py
@@ -174,7 +174,7 @@ class _rebuild_config(object):
 		rebuild_exclude = self._frozen_config.rebuild_exclude
 		rebuild_ignore = self._frozen_config.rebuild_ignore
 		if (self.rebuild and isinstance(parent, Package) and
-			parent.built and (priority.buildtime or priority.runtime) and
+			parent.built and priority.buildtime and
 			isinstance(dep_pkg, Package) and
 			not rebuild_exclude.findAtomForPackage(parent) and
 			not rebuild_ignore.findAtomForPackage(dep_pkg)):
@@ -209,66 +209,63 @@ class _rebuild_config(object):
 
 		return True
 
-	def _trigger_rebuild(self, parent, build_deps, runtime_deps):
+	def _trigger_rebuild(self, parent, build_deps):
 		root_slot = (parent.root, parent.slot_atom)
 		if root_slot in self.rebuild_list:
 			return False
 		trees = self._frozen_config.trees
-		children = set(build_deps).intersection(runtime_deps)
 		reinstall = False
-		for slot_atom in children:
-			kids = set([build_deps[slot_atom], runtime_deps[slot_atom]])
-			for dep_pkg in kids:
-				dep_root_slot = (dep_pkg.root, slot_atom)
-				if self._needs_rebuild(dep_pkg):
+		for slot_atom, dep_pkg in build_deps.items():
+			dep_root_slot = (dep_pkg.root, slot_atom)
+			if self._needs_rebuild(dep_pkg):
+				self.rebuild_list.add(root_slot)
+				return True
+			elif ("--usepkg" in self._frozen_config.myopts and
+				(dep_root_slot in self.reinstall_list or
+				dep_root_slot in self.rebuild_list or
+				not dep_pkg.installed)):
+
+				# A direct rebuild dependency is being installed. We
+				# should update the parent as well to the latest binary,
+				# if that binary is valid.
+				#
+				# To validate the binary, we check whether all of the
+				# rebuild dependencies are present on the same binhost.
+				#
+				# 1) If parent is present on the binhost, but one of its
+				#    rebuild dependencies is not, then the parent should
+				#    be rebuilt from source.
+				# 2) Otherwise, the parent binary is assumed to be valid,
+				#    because all of its rebuild dependencies are
+				#    consistent.
+				bintree = trees[parent.root]["bintree"]
+				uri = bintree.get_pkgindex_uri(parent.cpv)
+				dep_uri = bintree.get_pkgindex_uri(dep_pkg.cpv)
+				bindb = bintree.dbapi
+				if self.rebuild_if_new_ver and uri and uri != dep_uri:
+					cpv_norev = catpkgsplit(dep_pkg.cpv)[:-1]
+					for cpv in bindb.match(dep_pkg.slot_atom):
+						if cpv_norev == catpkgsplit(cpv)[:-1]:
+							dep_uri = bintree.get_pkgindex_uri(cpv)
+							if uri == dep_uri:
+								break
+				if uri and uri != dep_uri:
+					# 1) Remote binary package is invalid because it was
+					#    built without dep_pkg. Force rebuild.
 					self.rebuild_list.add(root_slot)
 					return True
-				elif ("--usepkg" in self._frozen_config.myopts and
-					(dep_root_slot in self.reinstall_list or
-					dep_root_slot in self.rebuild_list or
-					not dep_pkg.installed)):
-
-					# A direct rebuild dependency is being installed. We
-					# should update the parent as well to the latest binary,
-					# if that binary is valid.
-					#
-					# To validate the binary, we check whether all of the
-					# rebuild dependencies are present on the same binhost.
-					#
-					# 1) If parent is present on the binhost, but one of its
-					#    rebuild dependencies is not, then the parent should
-					#    be rebuilt from source.
-					# 2) Otherwise, the parent binary is assumed to be valid,
-					#    because all of its rebuild dependencies are
-					#    consistent.
-					bintree = trees[parent.root]["bintree"]
-					uri = bintree.get_pkgindex_uri(parent.cpv)
-					dep_uri = bintree.get_pkgindex_uri(dep_pkg.cpv)
-					bindb = bintree.dbapi
-					if self.rebuild_if_new_ver and uri and uri != dep_uri:
-						cpv_norev = catpkgsplit(dep_pkg.cpv)[:-1]
-						for cpv in bindb.match(dep_pkg.slot_atom):
-							if cpv_norev == catpkgsplit(cpv)[:-1]:
-								dep_uri = bintree.get_pkgindex_uri(cpv)
-								if uri == dep_uri:
-									break
-					if uri and uri != dep_uri:
-						# 1) Remote binary package is invalid because it was
-						#    built without dep_pkg. Force rebuild.
-						self.rebuild_list.add(root_slot)
-						return True
-					elif (parent.installed and
-						root_slot not in self.reinstall_list):
-						inst_build_time = parent.metadata.get("BUILD_TIME")
-						try:
-							bin_build_time, = bindb.aux_get(parent.cpv,
-								["BUILD_TIME"])
-						except KeyError:
-							continue
-						if bin_build_time != inst_build_time:
-							# 2) Remote binary package is valid, and local package
-							#    is not up to date. Force reinstall.
-							reinstall = True
+				elif (parent.installed and
+					root_slot not in self.reinstall_list):
+					inst_build_time = parent.metadata.get("BUILD_TIME")
+					try:
+						bin_build_time, = bindb.aux_get(parent.cpv,
+							["BUILD_TIME"])
+					except KeyError:
+						continue
+					if bin_build_time != inst_build_time:
+						# 2) Remote binary package is valid, and local package
+						#    is not up to date. Force reinstall.
+						reinstall = True
 		if reinstall:
 			self.reinstall_list.add(root_slot)
 		return reinstall
@@ -282,31 +279,15 @@ class _rebuild_config(object):
 		need_restart = False
 		graph = self._graph
 		build_deps = {}
-		runtime_deps = {}
-		leaf_nodes = deque(graph.leaf_nodes())
-
-		def ignore_non_runtime(priority):
-			return not priority.runtime
 
-		def ignore_non_buildtime(priority):
-			return not priority.buildtime
+		leaf_nodes = deque(graph.leaf_nodes())
 
 		# Trigger rebuilds bottom-up (starting with the leaves) so that parents
 		# will always know which children are being rebuilt.
 		while graph:
 			if not leaf_nodes:
-				# We're interested in intersection of buildtime and runtime,
-				# so ignore edges that do not contain both.
-				leaf_nodes.extend(graph.leaf_nodes(
-					ignore_priority=ignore_non_runtime))
-				if not leaf_nodes:
-					leaf_nodes.extend(graph.leaf_nodes(
-						ignore_priority=ignore_non_buildtime))
-					if not leaf_nodes:
-						# We'll have to drop an edge that is both
-						# buildtime and runtime. This should be
-						# quite rare.
-						leaf_nodes.append(graph.order[-1])
+				# We'll have to drop an edge. This should be quite rare.
+				leaf_nodes.append(graph.order[-1])
 
 			node = leaf_nodes.popleft()
 			if node not in graph:
@@ -315,32 +296,23 @@ class _rebuild_config(object):
 			slot_atom = node.slot_atom
 
 			# Remove our leaf node from the graph, keeping track of deps.
-			parents = graph.nodes[node][1].items()
+			parents = graph.parent_nodes(node)
 			graph.remove(node)
 			node_build_deps = build_deps.get(node, {})
-			node_runtime_deps = runtime_deps.get(node, {})
-			for parent, priorities in parents:
+			for parent in parents:
 				if parent == node:
 					# Ignore a direct cycle.
 					continue
 				parent_bdeps = build_deps.setdefault(parent, {})
-				parent_rdeps = runtime_deps.setdefault(parent, {})
-				for priority in priorities:
-					if priority.buildtime:
-						parent_bdeps[slot_atom] = node
-					if priority.runtime:
-						parent_rdeps[slot_atom] = node
-				if slot_atom in parent_bdeps and slot_atom in parent_rdeps:
-					parent_rdeps.update(node_runtime_deps)
+				parent_bdeps[slot_atom] = node
 				if not graph.child_nodes(parent):
 					leaf_nodes.append(parent)
 
 			# Trigger rebuilds for our leaf node. Because all of our children
-			# have been processed, build_deps and runtime_deps will be
-			# completely filled in, and self.rebuild_list / self.reinstall_list
-			# will tell us whether any of our children need to be rebuilt or
-			# reinstalled.
-			if self._trigger_rebuild(node, node_build_deps, node_runtime_deps):
+			# have been processed, the build_deps will be completely filled in,
+			# and self.rebuild_list / self.reinstall_list will tell us whether
+			# any of our children need to be rebuilt or reinstalled.
+			if self._trigger_rebuild(node, node_build_deps):
 				need_restart = True
 
 		return need_restart
diff --git a/pym/_emerge/help.py b/pym/_emerge/help.py
index c978ce2..57b376d 100644
--- a/pym/_emerge/help.py
+++ b/pym/_emerge/help.py
@@ -641,26 +641,24 @@ def help(myopts, havecolor=1):
 		print()
 		print("       " + green("--rebuild-if-new-rev") + " [ %s | %s ]" % \
 			(turquoise("y"), turquoise("n")))
-		desc = "Rebuild packages when dependencies that are " + \
-			"used at both build-time and run-time are built, " + \
-			"if the dependency is not already installed with the " + \
-			"same version and revision."
+		desc = "Rebuild packages when build-time dependencies are built " + \
+			"from source, if the dependency is not already installed with " + \
+			"the same version and revision."
 		for line in wrap(desc, desc_width):
 			print(desc_indent + line)
 		print()
 		print("       " + green("--rebuild-if-new-ver") + " [ %s | %s ]" % \
 			(turquoise("y"), turquoise("n")))
-		desc = "Rebuild packages when dependencies that are " + \
-			"used at both build-time and run-time are built, " + \
-			"if the dependency is not already installed with the " + \
-			"same version. Revision numbers are ignored."
+		desc = "Rebuild packages when build-time dependencies are built " + \
+			"from source, if the dependency is not already installed with " + \
+			"the same version. Revision numbers are ignored."
 		for line in wrap(desc, desc_width):
 			print(desc_indent + line)
 		print()
 		print("       " + green("--rebuild-if-unbuilt") + " [ %s | %s ]" % \
 			(turquoise("y"), turquoise("n")))
-		desc = "Rebuild packages when dependencies that are " + \
-			"used at both build-time and run-time are built."
+		desc = "Rebuild packages when build-time dependencies are built " + \
+			"from source"
 		for line in wrap(desc, desc_width):
 			print(desc_indent + line)
 		print()
diff --git a/pym/_emerge/search.py b/pym/_emerge/search.py
index 35f0412..3fed2b6 100644
--- a/pym/_emerge/search.py
+++ b/pym/_emerge/search.py
@@ -305,8 +305,9 @@ class search(object):
 					myebuild = self._findname(mycpv)
 					if myebuild:
 						pkgdir = os.path.dirname(myebuild)
-						from portage import manifest
-						mf = manifest.Manifest(
+						mf = self.settings.repositories.get_repo_for_location(
+							os.path.dirname(os.path.dirname(pkgdir)))
+						mf = mf.load_manifest(
 							pkgdir, self.settings["DISTDIR"])
 						try:
 							uri_map = self._getFetchMap(mycpv)
diff --git a/pym/portage/cache/template.py b/pym/portage/cache/template.py
index f84d8f4..8476836 100644
--- a/pym/portage/cache/template.py
+++ b/pym/portage/cache/template.py
@@ -30,6 +30,7 @@ class database(object):
 		self.readonly = readonly
 		self.sync_rate = 0
 		self.updates = 0
+		self.is_authoritative = False
 	
 	def __getitem__(self, cpv):
 		"""set a cpv to values
diff --git a/pym/portage/const.py b/pym/portage/const.py
index f108176..fac9fe5 100644
--- a/pym/portage/const.py
+++ b/pym/portage/const.py
@@ -86,7 +86,6 @@ EBUILD_PHASES            = ("pretend", "setup", "unpack", "prepare", "configure"
                            "package", "preinst", "postinst","prerm", "postrm",
                            "nofetch", "config", "info", "other")
 SUPPORTED_FEATURES       = frozenset([
-                           "allow-missing-manifests",
                            "assume-digests", "binpkg-logs", "buildpkg", "buildsyspkg", "candy",
                            "ccache", "chflags", "collision-protect", "compress-build-logs",
                            "digest", "distcc", "distcc-pump", "distlocks", "ebuild-locks", "fakeroot",
@@ -94,8 +93,8 @@ SUPPORTED_FEATURES       = frozenset([
                            "installsources", "keeptemp", "keepwork", "fixlafiles", "lmirror",
                            "metadata-transfer", "mirror", "multilib-strict", "news",
                            "noauto", "noclean", "nodoc", "noinfo", "noman",
-                           "nostrip", "notitles", "parallel-fetch", "parallel-install",
-                           "parse-eapi-ebuild-head",
+                           "nostrip", "notitles", "no-env-update", "parallel-fetch",
+                           "parallel-install", "parse-eapi-ebuild-head",
                            "prelink-checksums", "preserve-libs",
                            "protect-owned", "python-trace", "sandbox",
                            "selinux", "sesandbox", "sfperms",
diff --git a/pym/portage/dbapi/porttree.py b/pym/portage/dbapi/porttree.py
index bf8ecd9..3b164a3 100644
--- a/pym/portage/dbapi/porttree.py
+++ b/pym/portage/dbapi/porttree.py
@@ -195,10 +195,12 @@ class portdbapi(dbapi):
 				if x in self._pregen_auxdb:
 					continue
 				if os.path.isdir(os.path.join(x, "metadata", "cache")):
-					self._pregen_auxdb[x] = self.metadbmodule(
+					conf = self.repositories.get_repo_for_location(x)
+					cache = self._pregen_auxdb[x] = self.metadbmodule(
 						x, "metadata/cache", filtered_auxdbkeys, readonly=True)
+					cache.is_authoritative = conf.cache_is_authoritative
 					try:
-						self._pregen_auxdb[x].ec = self._repo_info[x].eclass_db
+						cache.ec = self._repo_info[x].eclass_db
 					except AttributeError:
 						pass
 		# Selectively cache metadata in order to optimize dep matching.
@@ -422,10 +424,11 @@ class portdbapi(dbapi):
 				eapi = metadata.get('EAPI', '').strip()
 				if not eapi:
 					eapi = '0'
-				if not (eapi[:1] == '-' and eapi_is_supported(eapi[1:])) and \
-					emtime == metadata['_mtime_'] and \
-					eclass_db.is_eclass_data_valid(metadata['_eclasses_']):
-					doregen = False
+				if not (eapi[:1] == '-' and eapi_is_supported(eapi[1:])):
+					if auxdb.is_authoritative or ( \
+						emtime == metadata['_mtime_'] and \
+						eclass_db.is_eclass_data_valid(metadata['_eclasses_'])):
+						doregen = False
 
 			if not doregen:
 				break
@@ -576,7 +579,9 @@ class portdbapi(dbapi):
 		if myebuild is None:
 			raise AssertionError(_("ebuild not found for '%s'") % mypkg)
 		pkgdir = os.path.dirname(myebuild)
-		mf = Manifest(pkgdir, self.settings["DISTDIR"])
+		mf = self.repositories.get_repo_for_location(
+			os.path.dirname(os.path.dirname(pkgdir))).load_manifest(
+				pkgdir, self.settings["DISTDIR"])
 		checksums = mf.getDigests()
 		if not checksums:
 			if debug: 
@@ -644,7 +649,9 @@ class portdbapi(dbapi):
 		if myebuild is None:
 			raise AssertionError(_("ebuild not found for '%s'") % mypkg)
 		pkgdir = os.path.dirname(myebuild)
-		mf = Manifest(pkgdir, self.settings["DISTDIR"])
+		mf = self.repositories.get_repo_for_location(
+			os.path.dirname(os.path.dirname(pkgdir)))
+		mf = mf.load_manifest(pkgdir, self.settings["DISTDIR"])
 		mysums = mf.getDigests()
 
 		failures = {}
diff --git a/pym/portage/dbapi/vartree.py b/pym/portage/dbapi/vartree.py
index 7f7873b..e6eee8b 100644
--- a/pym/portage/dbapi/vartree.py
+++ b/pym/portage/dbapi/vartree.py
@@ -60,6 +60,7 @@ from _emerge.PollScheduler import PollScheduler
 from _emerge.MiscFunctionsProcess import MiscFunctionsProcess
 
 import errno
+import fileinput
 import gc
 import io
 from itertools import chain
@@ -194,7 +195,7 @@ class vardbapi(dbapi):
 		"""
 		if self._lock_count:
 			self._lock_count += 1
-		else:
+		elif os.environ.get("PORTAGE_LOCKS") != "false":
 			if self._lock is not None:
 				raise AssertionError("already locked")
 			# At least the parent needs to exist for the lock file.
@@ -210,7 +211,7 @@ class vardbapi(dbapi):
 		"""
 		if self._lock_count > 1:
 			self._lock_count -= 1
-		else:
+		elif os.environ.get("PORTAGE_LOCKS") != "false":
 			if self._lock is None:
 				raise AssertionError("not locked")
 			self._lock_count = 0
@@ -1839,16 +1840,10 @@ class dblink(object):
 		else:
 			self.settings.pop("PORTAGE_LOG_FILE", None)
 
-		# Lock the config memory file to prevent symlink creation
-		# in merge_contents from overlapping with env-update.
-		self.vartree.dbapi._fs_lock()
-		try:
-			env_update(target_root=self.settings['ROOT'],
-				prev_mtimes=ldpath_mtimes,
-				contents=contents, env=self.settings.environ(),
-				writemsg_level=self._display_merge)
-		finally:
-			self.vartree.dbapi._fs_unlock()
+		env_update(target_root=self.settings['ROOT'],
+			prev_mtimes=ldpath_mtimes,
+			contents=contents, env=self.settings.environ(),
+			writemsg_level=self._display_merge, vardbapi=self.vartree.dbapi)
 
 		return os.EX_OK
 
@@ -3803,17 +3798,24 @@ class dblink(object):
 			if pkgcmp(catpkgsplit(self.pkg)[1:], catpkgsplit(v)[1:]) < 0:
 				downgrade = True
 
-		# Lock the config memory file to prevent symlink creation
-		# in merge_contents from overlapping with env-update.
-		self.vartree.dbapi._fs_lock()
-		try:
-			#update environment settings, library paths. DO NOT change symlinks.
-			env_update(makelinks=(not downgrade),
-				target_root=self.settings['ROOT'], prev_mtimes=prev_mtimes,
-				contents=contents, env=self.settings.environ(),
-				writemsg_level=self._display_merge)
-		finally:
-			self.vartree.dbapi._fs_unlock()
+		#update environment settings, library paths. DO NOT change symlinks.
+		env_update(makelinks=(not downgrade),
+			target_root=self.settings['ROOT'], prev_mtimes=prev_mtimes,
+			contents=contents, env=self.settings.environ(),
+			writemsg_level=self._display_merge, vardbapi=self.vartree.dbapi)
+
+		# Fix *.la files to point to libs in target_root, if they
+		# don't do so already.
+		re_root = self.settings["ROOT"].strip("/")
+		if re_root:
+			fix_files = []
+			for path in contents:
+				if path.endswith(".la"):
+					if os.path.exists(path): fix_files.append(path)
+			if fix_files:
+				pat = re.compile(r"([' =](?:-[IL])?/)(usr|lib|opt)")
+				for line in fileinput.input(fix_files, inplace=1):
+					sys.stdout.write(pat.sub(r"\1%s/\2" % re_root, line))
 
 		# For gcc upgrades, preserved libs have to be removed after the
 		# the library path has been updated.
diff --git a/pym/portage/manifest.py b/pym/portage/manifest.py
index 13efab7..b2f96e6 100644
--- a/pym/portage/manifest.py
+++ b/pym/portage/manifest.py
@@ -49,6 +49,12 @@ def guessManifestFileType(filename):
 	else:
 		return "DIST"
 
+def guessThinManifestFileType(filename):
+	type = guessManifestFileType(filename)
+	if type != "DIST":
+		return None
+	return "DIST"
+
 def parseManifest2(mysplit):
 	myentry = None
 	if len(mysplit) > 4 and mysplit[0] in portage.const.MANIFEST2_IDENTIFIERS:
@@ -93,12 +99,15 @@ class Manifest2Entry(ManifestEntry):
 class Manifest(object):
 	parsers = (parseManifest2,)
 	def __init__(self, pkgdir, distdir, fetchlist_dict=None,
-		manifest1_compat=False, from_scratch=False):
+		manifest1_compat=False, from_scratch=False, thin=False, allow_missing=False,
+		allow_create=True):
 		""" create new Manifest instance for package in pkgdir
 		    and add compability entries for old portage versions if manifest1_compat == True.
 		    Do not parse Manifest file if from_scratch == True (only for internal use)
 			The fetchlist_dict parameter is required only for generation of
-			a Manifest (not needed for parsing and checking sums)."""
+			a Manifest (not needed for parsing and checking sums).
+			If thin is specified, then the manifest carries only info for
+			distfiles."""
 		self.pkgdir = _unicode_decode(pkgdir).rstrip(os.sep) + os.sep
 		self.fhashdict = {}
 		self.hashes = set()
@@ -120,7 +129,13 @@ class Manifest(object):
 		else:
 			self.fetchlist_dict = {}
 		self.distdir = distdir
-		self.guessType = guessManifestFileType
+		self.thin = thin
+		if thin:
+			self.guessType = guessThinManifestFileType
+		else:
+			self.guessType = guessManifestFileType
+		self.allow_missing = allow_missing
+		self.allow_create = allow_create
 
 	def getFullname(self):
 		""" Returns the absolute path to the Manifest file for this instance """
@@ -223,11 +238,13 @@ class Manifest(object):
 
 	def write(self, sign=False, force=False):
 		""" Write Manifest instance to disk, optionally signing it """
+		if not self.allow_create:
+			return
 		self.checkIntegrity()
 		try:
 			myentries = list(self._createManifestEntries())
 			update_manifest = True
-			if not force:
+			if myentries and not force:
 				try:
 					f = io.open(_unicode_encode(self.getFullname(),
 						encoding=_encodings['fs'], errors='strict'),
@@ -246,9 +263,20 @@ class Manifest(object):
 						pass
 					else:
 						raise
+
 			if update_manifest:
-				write_atomic(self.getFullname(),
-					"".join("%s\n" % str(myentry) for myentry in myentries))
+				if myentries or not (self.thin or self.allow_missing):
+					write_atomic(self.getFullname(), "".join("%s\n" %
+						str(myentry) for myentry in myentries))
+				else:
+					# With thin manifest, there's no need to have
+					# a Manifest file if there are no DIST entries.
+					try:
+						os.unlink(self.getFullname())
+					except OSError as e:
+						if e.errno != errno.ENOENT:
+							raise
+
 			if sign:
 				self.sign()
 		except (IOError, OSError) as e:
@@ -305,6 +333,8 @@ class Manifest(object):
 		distfiles to raise a FileNotFound exception for (if no file or existing
 		checksums are available), and defaults to all distfiles when not
 		specified."""
+		if not self.allow_create:
+			return
 		if checkExisting:
 			self.checkAllHashes()
 		if assumeDistHashesSometimes or assumeDistHashesAlways:
@@ -313,64 +343,20 @@ class Manifest(object):
 			distfilehashes = {}
 		self.__init__(self.pkgdir, self.distdir,
 			fetchlist_dict=self.fetchlist_dict, from_scratch=True,
-			manifest1_compat=False)
-		cpvlist = []
+			manifest1_compat=False, thin=self.thin)
 		pn = os.path.basename(self.pkgdir.rstrip(os.path.sep))
 		cat = self._pkgdir_category()
 
 		pkgdir = self.pkgdir
+		if self.thin:
+			cpvlist = self._update_thin_pkgdir(cat, pn, pkgdir)
+		else:
+			cpvlist = self._update_thick_pkgdir(cat, pn, pkgdir)
 
-		for pkgdir, pkgdir_dirs, pkgdir_files in os.walk(pkgdir):
-			break
-		for f in pkgdir_files:
-			try:
-				f = _unicode_decode(f,
-					encoding=_encodings['fs'], errors='strict')
-			except UnicodeDecodeError:
-				continue
-			if f[:1] == ".":
-				continue
-			pf = None
-			if f[-7:] == '.ebuild':
-				pf = f[:-7]
-			if pf is not None:
-				mytype = "EBUILD"
-				ps = portage.versions._pkgsplit(pf)
-				cpv = "%s/%s" % (cat, pf)
-				if not ps:
-					raise PortagePackageException(
-						_("Invalid package name: '%s'") % cpv)
-				if ps[0] != pn:
-					raise PortagePackageException(
-						_("Package name does not "
-						"match directory name: '%s'") % cpv)
-				cpvlist.append(cpv)
-			elif manifest2MiscfileFilter(f):
-				mytype = "MISC"
-			else:
-				continue
-			self.fhashdict[mytype][f] = perform_multiple_checksums(self.pkgdir+f, self.hashes)
-		recursive_files = []
-
-		pkgdir = self.pkgdir
-		cut_len = len(os.path.join(pkgdir, "files") + os.sep)
-		for parentdir, dirs, files in os.walk(os.path.join(pkgdir, "files")):
-			for f in files:
-				try:
-					f = _unicode_decode(f,
-						encoding=_encodings['fs'], errors='strict')
-				except UnicodeDecodeError:
-					continue
-				full_path = os.path.join(parentdir, f)
-				recursive_files.append(full_path[cut_len:])
-		for f in recursive_files:
-			if not manifest2AuxfileFilter(f):
-				continue
-			self.fhashdict["AUX"][f] = perform_multiple_checksums(
-				os.path.join(self.pkgdir, "files", f.lstrip(os.sep)), self.hashes)
 		distlist = set()
 		for cpv in cpvlist:
 			distlist.update(self._getCpvDistfiles(cpv))
+
 		if requiredDistfiles is None:
 			# This allows us to force removal of stale digests for the
 			# ebuild --force digest option (no distfiles are required).
@@ -404,6 +390,81 @@ class Manifest(object):
 					if f in requiredDistfiles:
 						raise
 
+	def _is_cpv(self, cat, pn, filename):
+		if not filename.endswith(".ebuild"):
+			return None
+		pf = filename[:-7]
+		if pf is None:
+			return None
+		ps = portage.versions._pkgsplit(pf)
+		cpv = "%s/%s" % (cat, pf)
+		if not ps:
+			raise PortagePackageException(
+				_("Invalid package name: '%s'") % cpv)
+		if ps[0] != pn:
+			raise PortagePackageException(
+				_("Package name does not "
+				"match directory name: '%s'") % cpv)
+		return cpv
+
+	def _update_thin_pkgdir(self, cat, pn, pkgdir):
+		for pkgdir, pkgdir_dirs, pkgdir_files in os.walk(pkgdir):
+			break
+		cpvlist = []
+		for f in pkgdir_files:
+			try:
+				f = _unicode_decode(f,
+					encoding=_encodings['fs'], errors='strict')
+			except UnicodeDecodeError:
+				continue
+			if f[:1] == '.':
+				continue
+			pf = self._is_cpv(cat, pn, f)
+			if pf is not None:
+				cpvlist.append(pf)
+		return cpvlist
+
+	def _update_thick_pkgdir(self, cat, pn, pkgdir):
+		cpvlist = []
+		for pkgdir, pkgdir_dirs, pkgdir_files in os.walk(pkgdir):
+			break
+		for f in pkgdir_files:
+			try:
+				f = _unicode_decode(f,
+					encoding=_encodings['fs'], errors='strict')
+			except UnicodeDecodeError:
+				continue
+			if f[:1] == ".":
+				continue
+			pf = self._is_cpv(cat, pn, f)
+			if pf is not None:
+				mytype = "EBUILD"
+				cpvlist.append(pf)
+			elif manifest2MiscfileFilter(f):
+				mytype = "MISC"
+			else:
+				continue
+			self.fhashdict[mytype][f] = perform_multiple_checksums(self.pkgdir+f, self.hashes)
+		recursive_files = []
+
+		pkgdir = self.pkgdir
+		cut_len = len(os.path.join(pkgdir, "files") + os.sep)
+		for parentdir, dirs, files in os.walk(os.path.join(pkgdir, "files")):
+			for f in files:
+				try:
+					f = _unicode_decode(f,
+						encoding=_encodings['fs'], errors='strict')
+				except UnicodeDecodeError:
+					continue
+				full_path = os.path.join(parentdir, f)
+				recursive_files.append(full_path[cut_len:])
+		for f in recursive_files:
+			if not manifest2AuxfileFilter(f):
+				continue
+			self.fhashdict["AUX"][f] = perform_multiple_checksums(
+				os.path.join(self.pkgdir, "files", f.lstrip(os.sep)), self.hashes)
+		return cpvlist
+
 	def _pkgdir_category(self):
 		return self.pkgdir.rstrip(os.sep).split(os.sep)[-2]
 
diff --git a/pym/portage/package/ebuild/digestcheck.py b/pym/portage/package/ebuild/digestcheck.py
index 1e34b14..f761f60 100644
--- a/pym/portage/package/ebuild/digestcheck.py
+++ b/pym/portage/package/ebuild/digestcheck.py
@@ -28,45 +28,27 @@ def digestcheck(myfiles, mysettings, strict=False, justmanifest=None, mf=None):
 
 	if mysettings.get("EBUILD_SKIP_MANIFEST") == "1":
 		return 1
-	allow_missing = "allow-missing-manifests" in mysettings.features
 	pkgdir = mysettings["O"]
-	manifest_path = os.path.join(pkgdir, "Manifest")
-	if not os.path.exists(manifest_path):
-		if allow_missing:
-			return 1
-		writemsg(_("!!! Manifest file not found: '%s'\n") % manifest_path,
-			noiselevel=-1)
-		if strict:
-			return 0
-		else:
-			return 1
 	if mf is None:
-		mf = Manifest(pkgdir, mysettings["DISTDIR"])
-	manifest_empty = True
-	for d in mf.fhashdict.values():
-		if d:
-			manifest_empty = False
-			break
-	if manifest_empty:
-		writemsg(_("!!! Manifest is empty: '%s'\n") % manifest_path,
-			noiselevel=-1)
-		if strict:
-			return 0
-		else:
-			return 1
+		mf = mysettings.repositories.get_repo_for_location(
+			os.path.dirname(os.path.dirname(pkgdir)))
+		mf = mf.load_manifest(pkgdir, mysettings["DISTDIR"])
 	eout = EOutput()
 	eout.quiet = mysettings.get("PORTAGE_QUIET", None) == "1"
 	try:
 		if strict and "PORTAGE_PARALLEL_FETCHONLY" not in mysettings:
-			eout.ebegin(_("checking ebuild checksums ;-)"))
-			mf.checkTypeHashes("EBUILD")
-			eout.eend(0)
-			eout.ebegin(_("checking auxfile checksums ;-)"))
-			mf.checkTypeHashes("AUX")
-			eout.eend(0)
-			eout.ebegin(_("checking miscfile checksums ;-)"))
-			mf.checkTypeHashes("MISC", ignoreMissingFiles=True)
-			eout.eend(0)
+			if mf.fhashdict.get("EBUILD"):
+				eout.ebegin(_("checking ebuild checksums ;-)"))
+				mf.checkTypeHashes("EBUILD")
+				eout.eend(0)
+			if mf.fhashdict.get("AUX"):
+				eout.ebegin(_("checking auxfile checksums ;-)"))
+				mf.checkTypeHashes("AUX")
+				eout.eend(0)
+			if mf.fhashdict.get("MISC"):
+				eout.ebegin(_("checking miscfile checksums ;-)"))
+				mf.checkTypeHashes("MISC", ignoreMissingFiles=True)
+				eout.eend(0)
 		for f in myfiles:
 			eout.ebegin(_("checking %s ;-)") % f)
 			ftype = mf.findFile(f)
@@ -90,7 +72,7 @@ def digestcheck(myfiles, mysettings, strict=False, justmanifest=None, mf=None):
 		writemsg(_("!!! Got: %s\n") % e.value[2], noiselevel=-1)
 		writemsg(_("!!! Expected: %s\n") % e.value[3], noiselevel=-1)
 		return 0
-	if allow_missing:
+	if mf.thin or mf.allow_missing:
 		# In this case we ignore any missing digests that
 		# would otherwise be detected below.
 		return 1
diff --git a/pym/portage/package/ebuild/digestgen.py b/pym/portage/package/ebuild/digestgen.py
index eb7210e..f7cf149 100644
--- a/pym/portage/package/ebuild/digestgen.py
+++ b/pym/portage/package/ebuild/digestgen.py
@@ -53,8 +53,15 @@ def digestgen(myarchives=None, mysettings=None, myportdb=None):
 				return 0
 		mytree = os.path.dirname(os.path.dirname(mysettings["O"]))
 		manifest1_compat = False
-		mf = Manifest(mysettings["O"], mysettings["DISTDIR"],
+		mf = mysettings.repositories.get_repo_for_location(mytree)
+		mf = mf.load_manifest(mysettings["O"], mysettings["DISTDIR"],
 			fetchlist_dict=fetchlist_dict, manifest1_compat=manifest1_compat)
+
+		if not mf.allow_create:
+			writemsg_stdout(_(">>> Skipping creating Manifest for %s; "
+				"repository is configured to not use them\n") % mysettings["O"])
+			return 1
+
 		# Don't require all hashes since that can trigger excessive
 		# fetches when sufficient digests already exist.  To ease transition
 		# while Manifest 1 is being removed, only require hashes that will
diff --git a/pym/portage/package/ebuild/doebuild.py b/pym/portage/package/ebuild/doebuild.py
index a710e09..8c0cced 100644
--- a/pym/portage/package/ebuild/doebuild.py
+++ b/pym/portage/package/ebuild/doebuild.py
@@ -3,6 +3,7 @@
 
 __all__ = ['doebuild', 'doebuild_environment', 'spawn', 'spawnebuild']
 
+import fileinput
 import gzip
 import errno
 import io
@@ -50,7 +51,6 @@ from portage.exception import DigestException, FileNotFound, \
 	IncorrectParameter, InvalidDependString, PermissionDenied, \
 	UnsupportedAPIException
 from portage.localization import _
-from portage.manifest import Manifest
 from portage.output import style_to_ansi_code
 from portage.package.ebuild.prepare_build_dirs import prepare_build_dirs
 from portage.util import apply_recursive_permissions, \
@@ -480,21 +480,27 @@ def doebuild(myebuild, mydo, myroot, mysettings, debug=0, listonly=0,
 		return 1
 
 	global _doebuild_manifest_cache
+	pkgdir = os.path.dirname(myebuild)
+	manifest_path = os.path.join(pkgdir, "Manifest")
+	if tree == "porttree":
+		repo_config = mysettings.repositories.get_repo_for_location(
+			os.path.dirname(os.path.dirname(pkgdir)))
+	else:
+		repo_config = None
 	mf = None
 	if "strict" in features and \
 		"digest" not in features and \
 		tree == "porttree" and \
+		not repo_config.thin_manifest and \
 		mydo not in ("digest", "manifest", "help") and \
-		not portage._doebuild_manifest_exempt_depend:
+		not portage._doebuild_manifest_exempt_depend and \
+		not (repo_config.allow_missing_manifest and not os.path.exists(manifest_path)):
 		# Always verify the ebuild checksums before executing it.
 		global _doebuild_broken_ebuilds
 
 		if myebuild in _doebuild_broken_ebuilds:
 			return 1
 
-		pkgdir = os.path.dirname(myebuild)
-		manifest_path = os.path.join(pkgdir, "Manifest")
-
 		# Avoid checking the same Manifest several times in a row during a
 		# regen with an empty cache.
 		if _doebuild_manifest_cache is None or \
@@ -505,7 +511,7 @@ def doebuild(myebuild, mydo, myroot, mysettings, debug=0, listonly=0,
 				out.eerror(_("Manifest not found for '%s'") % (myebuild,))
 				_doebuild_broken_ebuilds.add(myebuild)
 				return 1
-			mf = Manifest(pkgdir, mysettings["DISTDIR"])
+			mf = repo_config.load_manifest(pkgdir, mysettings["DISTDIR"])
 
 		else:
 			mf = _doebuild_manifest_cache
@@ -513,10 +519,12 @@ def doebuild(myebuild, mydo, myroot, mysettings, debug=0, listonly=0,
 		try:
 			mf.checkFileHashes("EBUILD", os.path.basename(myebuild))
 		except KeyError:
-			out = portage.output.EOutput()
-			out.eerror(_("Missing digest for '%s'") % (myebuild,))
-			_doebuild_broken_ebuilds.add(myebuild)
-			return 1
+			if not (mf.allow_missing and
+				os.path.basename(myebuild) not in mf.fhashdict["EBUILD"]):
+				out = portage.output.EOutput()
+				out.eerror(_("Missing digest for '%s'") % (myebuild,))
+				_doebuild_broken_ebuilds.add(myebuild)
+				return 1
 		except FileNotFound:
 			out = portage.output.EOutput()
 			out.eerror(_("A file listed in the Manifest "
@@ -536,7 +544,7 @@ def doebuild(myebuild, mydo, myroot, mysettings, debug=0, listonly=0,
 		if mf.getFullname() in _doebuild_broken_manifests:
 			return 1
 
-		if mf is not _doebuild_manifest_cache:
+		if mf is not _doebuild_manifest_cache and not mf.allow_missing:
 
 			# Make sure that all of the ebuilds are
 			# actually listed in the Manifest.
@@ -553,8 +561,8 @@ def doebuild(myebuild, mydo, myroot, mysettings, debug=0, listonly=0,
 					_doebuild_broken_manifests.add(manifest_path)
 					return 1
 
-			# Only cache it if the above stray files test succeeds.
-			_doebuild_manifest_cache = mf
+		# We cache it only after all above checks succeed.
+		_doebuild_manifest_cache = mf
 
 	logfile=None
 	builddir_lock = None
@@ -1300,7 +1308,8 @@ _post_phase_cmds = {
 
 	"install" : [
 		"install_qa_check",
-		"install_symlink_html_docs"],
+		"install_symlink_html_docs",
+		"install_hooks"],
 
 	"preinst" : [
 		"preinst_sfperms",
@@ -1497,6 +1506,7 @@ def _post_src_install_uid_fix(mysettings, out):
 
 	destdir = mysettings["D"]
 	unicode_errors = []
+	fix_files = []
 
 	while True:
 
@@ -1585,10 +1595,12 @@ def _post_src_install_uid_fix(mysettings, out):
 							new_contents, mode='wb')
 
 				mystat = os.lstat(fpath)
-				if stat.S_ISREG(mystat.st_mode) and \
-					mystat.st_ino not in counted_inodes:
-					counted_inodes.add(mystat.st_ino)
-					size += mystat.st_size
+				if stat.S_ISREG(mystat.st_mode):
+					if fname.endswith(".la"):
+						fix_files.append(fpath)
+					if mystat.st_ino not in counted_inodes:
+						counted_inodes.add(mystat.st_ino)
+						size += mystat.st_size
 				if mystat.st_uid != portage_uid and \
 					mystat.st_gid != portage_gid:
 					continue
@@ -1656,6 +1668,14 @@ def _post_src_install_uid_fix(mysettings, out):
 			mode='w', encoding=_encodings['repo.content'],
 			errors='strict').write(_unicode_decode(v + '\n'))
 
+	re_root = mysettings["ROOT"].strip("/")
+	if fix_files and re_root:
+		# Replace references to our sysroot with references to "/" in binpkg.
+		# Sysroot will be re-appended when the package is installed.
+		pat = re.compile(r"([' =](-[IL])?/)%s/" % re.escape(re_root))
+		for line in fileinput.input(fix_files, inplace=1):
+			sys.stdout.write(pat.sub(r"\1", line))
+
 	_reapply_bsdflags_to_image(mysettings)
 
 def _reapply_bsdflags_to_image(mysettings):
diff --git a/pym/portage/package/ebuild/fetch.py b/pym/portage/package/ebuild/fetch.py
index 5cbbf87..11c4c01 100644
--- a/pym/portage/package/ebuild/fetch.py
+++ b/pym/portage/package/ebuild/fetch.py
@@ -356,7 +356,8 @@ def fetch(myuris, mysettings, listonly=0, fetchonly=0,
 		allow_missing_digests = True
 	pkgdir = mysettings.get("O")
 	if digests is None and not (pkgdir is None or skip_manifest):
-		mydigests = Manifest(
+		mydigests = mysettings.repositories.get_repo_for_location(
+			os.path.dirname(os.path.dirname(pkgdir))).load_manifest(
 			pkgdir, mysettings["DISTDIR"]).getTypeDigests("DIST")
 	elif digests is None or skip_manifest:
 		# no digests because fetch was not called for a specific package
diff --git a/pym/portage/repository/config.py b/pym/portage/repository/config.py
index 9f0bb99..c582148 100644
--- a/pym/portage/repository/config.py
+++ b/pym/portage/repository/config.py
@@ -16,6 +16,7 @@ from portage.util import normalize_path, writemsg, writemsg_level, shlex_split
 from portage.localization import _
 from portage import _unicode_encode
 from portage import _encodings
+from portage import manifest
 
 _repo_name_sub_re = re.compile(r'[^\w-]')
 
@@ -36,7 +37,8 @@ class RepoConfig(object):
 	"""Stores config of one repository"""
 
 	__slots__ = ['aliases', 'eclass_overrides', 'eclass_locations', 'location', 'user_location', 'masters', 'main_repo',
-		'missing_repo_name', 'name', 'priority', 'sync', 'format']
+		'missing_repo_name', 'name', 'priority', 'sync', 'format', 'sign_manifest', 'thin_manifest',
+		'allow_missing_manifest', 'create_manifest', 'disable_manifest', 'cache_is_authoritative']
 
 	def __init__(self, name, repo_opts):
 		"""Build a RepoConfig with options in repo_opts
@@ -105,6 +107,19 @@ class RepoConfig(object):
 			missing = False
 		self.name = name
 		self.missing_repo_name = missing
+		self.thin_manifest = False
+		self.allow_missing_manifest = False
+		self.create_manifest = True
+		self.disable_manifest = False
+		self.cache_is_authoritative = False
+
+	def load_manifest(self, *args, **kwds):
+		kwds['thin'] = self.thin_manifest
+		kwds['allow_missing'] = self.allow_missing_manifest
+		kwds['allow_create'] = self.create_manifest
+		if self.disable_manifest:
+			kwds['from_scratch'] = True
+		return manifest.Manifest(*args, **kwds)
 
 	def update(self, new_repo):
 		"""Update repository with options in another RepoConfig"""
@@ -169,107 +184,101 @@ class RepoConfig(object):
 
 class RepoConfigLoader(object):
 	"""Loads and store config of several repositories, loaded from PORTDIR_OVERLAY or repos.conf"""
-	def __init__(self, paths, settings):
-		"""Load config from files in paths"""
-		def parse(paths, prepos, ignored_map, ignored_location_map):
-			"""Parse files in paths to load config"""
-			parser = SafeConfigParser()
-			try:
-				parser.read(paths)
-			except ParsingError as e:
-				writemsg(_("!!! Error while reading repo config file: %s\n") % e, noiselevel=-1)
-			prepos['DEFAULT'] = RepoConfig("DEFAULT", parser.defaults())
-			for sname in parser.sections():
-				optdict = {}
-				for oname in parser.options(sname):
-					optdict[oname] = parser.get(sname, oname)
-
-				repo = RepoConfig(sname, optdict)
-				if repo.location and not os.path.exists(repo.location):
-					writemsg(_("!!! Invalid repos.conf entry '%s'"
-						" (not a dir): '%s'\n") % (sname, repo.location), noiselevel=-1)
-					continue
 
-				if repo.name in prepos:
-					old_location = prepos[repo.name].location
-					if old_location is not None and repo.location is not None and old_location != repo.location:
-						ignored_map.setdefault(repo.name, []).append(old_location)
-						ignored_location_map[old_location] = repo.name
-					prepos[repo.name].update(repo)
-				else:
-					prepos[repo.name] = repo
-
-		def add_overlays(portdir, portdir_overlay, prepos, ignored_map, ignored_location_map):
-			"""Add overlays in PORTDIR_OVERLAY as repositories"""
-			overlays = []
-			if portdir:
-				portdir = normalize_path(portdir)
-				overlays.append(portdir)
-			port_ov = [normalize_path(i) for i in shlex_split(portdir_overlay)]
-			overlays.extend(port_ov)
-			default_repo_opts = {}
-			if prepos['DEFAULT'].aliases is not None:
-				default_repo_opts['aliases'] = \
-					' '.join(prepos['DEFAULT'].aliases)
-			if prepos['DEFAULT'].eclass_overrides is not None:
-				default_repo_opts['eclass-overrides'] = \
-					' '.join(prepos['DEFAULT'].eclass_overrides)
-			if prepos['DEFAULT'].masters is not None:
-				default_repo_opts['masters'] = \
-					' '.join(prepos['DEFAULT'].masters)
-			if overlays:
-				#overlay priority is negative because we want them to be looked before any other repo
-				base_priority = 0
-				for ov in overlays:
-					if os.path.isdir(ov):
-						repo_opts = default_repo_opts.copy()
-						repo_opts['location'] = ov
-						repo = RepoConfig(None, repo_opts)
-						repo_conf_opts = prepos.get(repo.name)
-						if repo_conf_opts is not None:
-							if repo_conf_opts.aliases is not None:
-								repo_opts['aliases'] = \
-									' '.join(repo_conf_opts.aliases)
-							if repo_conf_opts.eclass_overrides is not None:
-								repo_opts['eclass-overrides'] = \
-									' '.join(repo_conf_opts.eclass_overrides)
-							if repo_conf_opts.masters is not None:
-								repo_opts['masters'] = \
-									' '.join(repo_conf_opts.masters)
-						repo = RepoConfig(repo.name, repo_opts)
-						if repo.name in prepos:
-							old_location = prepos[repo.name].location
-							if old_location is not None and old_location != repo.location:
-								ignored_map.setdefault(repo.name, []).append(old_location)
-								ignored_location_map[old_location] = repo.name
-								if old_location == portdir:
-									portdir = repo.user_location
-							prepos[repo.name].update(repo)
-							repo = prepos[repo.name]
-						else:
-							prepos[repo.name] = repo
-
-						if ov == portdir and portdir not in port_ov:
-							repo.priority = -1000
-						else:
-							repo.priority = base_priority
-							base_priority += 1
+	@staticmethod
+	def _add_overlays(portdir, portdir_overlay, prepos, ignored_map, ignored_location_map):
+		"""Add overlays in PORTDIR_OVERLAY as repositories"""
+		overlays = []
+		if portdir:
+			portdir = normalize_path(portdir)
+			overlays.append(portdir)
+		port_ov = [normalize_path(i) for i in shlex_split(portdir_overlay)]
+		overlays.extend(port_ov)
+		default_repo_opts = {}
+		if prepos['DEFAULT'].aliases is not None:
+			default_repo_opts['aliases'] = \
+				' '.join(prepos['DEFAULT'].aliases)
+		if prepos['DEFAULT'].eclass_overrides is not None:
+			default_repo_opts['eclass-overrides'] = \
+				' '.join(prepos['DEFAULT'].eclass_overrides)
+		if prepos['DEFAULT'].masters is not None:
+			default_repo_opts['masters'] = \
+				' '.join(prepos['DEFAULT'].masters)
+		if overlays:
+			#overlay priority is negative because we want them to be looked before any other repo
+			base_priority = 0
+			for ov in overlays:
+				if os.path.isdir(ov):
+					repo_opts = default_repo_opts.copy()
+					repo_opts['location'] = ov
+					repo = RepoConfig(None, repo_opts)
+					repo_conf_opts = prepos.get(repo.name)
+					if repo_conf_opts is not None:
+						if repo_conf_opts.aliases is not None:
+							repo_opts['aliases'] = \
+								' '.join(repo_conf_opts.aliases)
+						if repo_conf_opts.eclass_overrides is not None:
+							repo_opts['eclass-overrides'] = \
+								' '.join(repo_conf_opts.eclass_overrides)
+						if repo_conf_opts.masters is not None:
+							repo_opts['masters'] = \
+								' '.join(repo_conf_opts.masters)
+					repo = RepoConfig(repo.name, repo_opts)
+					if repo.name in prepos:
+						old_location = prepos[repo.name].location
+						if old_location is not None and old_location != repo.location:
+							ignored_map.setdefault(repo.name, []).append(old_location)
+							ignored_location_map[old_location] = repo.name
+							if old_location == portdir:
+								portdir = repo.user_location
+						prepos[repo.name].update(repo)
+						repo = prepos[repo.name]
+					else:
+						prepos[repo.name] = repo
 
+					if ov == portdir and portdir not in port_ov:
+						repo.priority = -1000
 					else:
-						writemsg(_("!!! Invalid PORTDIR_OVERLAY"
-							" (not a dir): '%s'\n") % ov, noiselevel=-1)
+						repo.priority = base_priority
+						base_priority += 1
+
+				else:
+					writemsg(_("!!! Invalid PORTDIR_OVERLAY"
+						" (not a dir): '%s'\n") % ov, noiselevel=-1)
+
+		return portdir
+
+	@staticmethod
+	def _parse(paths, prepos, ignored_map, ignored_location_map):
+		"""Parse files in paths to load config"""
+		parser = SafeConfigParser()
+		try:
+			parser.read(paths)
+		except ParsingError as e:
+			writemsg(_("!!! Error while reading repo config file: %s\n") % e, noiselevel=-1)
+		prepos['DEFAULT'] = RepoConfig("DEFAULT", parser.defaults())
+		for sname in parser.sections():
+			optdict = {}
+			for oname in parser.options(sname):
+				optdict[oname] = parser.get(sname, oname)
+
+			repo = RepoConfig(sname, optdict)
+			if repo.location and not os.path.exists(repo.location):
+				writemsg(_("!!! Invalid repos.conf entry '%s'"
+					" (not a dir): '%s'\n") % (sname, repo.location), noiselevel=-1)
+				continue
 
-			return portdir
+			if repo.name in prepos:
+				old_location = prepos[repo.name].location
+				if old_location is not None and repo.location is not None and old_location != repo.location:
+					ignored_map.setdefault(repo.name, []).append(old_location)
+					ignored_location_map[old_location] = repo.name
+				prepos[repo.name].update(repo)
+			else:
+				prepos[repo.name] = repo
 
-		def repo_priority(r):
-			"""
-			Key funtion for comparing repositories by priority.
-			None is equal priority zero.
-			"""
-			x = prepos[r].priority
-			if x is None:
-				return 0
-			return x
+	def __init__(self, paths, settings):
+		"""Load config from files in paths"""
 
 		prepos = {}
 		location_map = {}
@@ -279,10 +288,12 @@ class RepoConfigLoader(object):
 
 		portdir = settings.get('PORTDIR', '')
 		portdir_overlay = settings.get('PORTDIR_OVERLAY', '')
-		parse(paths, prepos, ignored_map, ignored_location_map)
+
+		self._parse(paths, prepos, ignored_map, ignored_location_map)
+
 		# If PORTDIR_OVERLAY contains a repo with the same repo_name as
 		# PORTDIR, then PORTDIR is overridden.
-		portdir = add_overlays(portdir, portdir_overlay, prepos,
+		portdir = self._add_overlays(portdir, portdir_overlay, prepos,
 			ignored_map, ignored_location_map)
 		if portdir and portdir.strip():
 			portdir = os.path.realpath(portdir)
@@ -319,6 +330,15 @@ class RepoConfigLoader(object):
 					aliases.extend(repo.aliases)
 				repo.aliases = tuple(sorted(set(aliases)))
 
+			if layout_data.get('thin-manifests', '').lower() == 'true':
+				repo.thin_manifest = True
+
+			manifest_policy = layout_data.get('use-manifests', 'strict').lower()
+			repo.allow_missing_manifest = manifest_policy != 'strict'
+			repo.create_manifest = manifest_policy != 'false'
+			repo.disable_manifest = manifest_policy == 'false'
+			repo.cache_is_authoritative = layout_data.get('authoritative-cache', 'false').lower() == 'true'
+
 		#Take aliases into account.
 		new_prepos = {}
 		for repo_name, repo in prepos.items():
@@ -342,9 +362,11 @@ class RepoConfigLoader(object):
 
 		# filter duplicates from aliases, by only including
 		# items where repo.name == key
-		prepos_order = [repo.name for key, repo in prepos.items() \
+
+		prepos_order = sorted(prepos.items(), key=lambda r:r[1].priority or 0)
+
+		prepos_order = [repo.name for (key, repo) in prepos_order
 			if repo.name == key and repo.location is not None]
-		prepos_order.sort(key=repo_priority)
 
 		if portdir in location_map:
 			portdir_repo = prepos[location_map[portdir]]
@@ -488,6 +510,9 @@ class RepoConfigLoader(object):
 			return None
 		return self.treemap[repo_name]
 
+	def get_repo_for_location(self, location):
+		return self.prepos[self.get_name_for_location(location)]
+
 	def __getitem__(self, repo_name):
 		return self.prepos[repo_name]
 
diff --git a/pym/portage/tests/resolver/test_rebuild.py b/pym/portage/tests/resolver/test_rebuild.py
index b9c4d6d..6f1a783 100644
--- a/pym/portage/tests/resolver/test_rebuild.py
+++ b/pym/portage/tests/resolver/test_rebuild.py
@@ -9,57 +9,58 @@ class RebuildTestCase(TestCase):
 
 	def testRebuild(self):
 		"""
-		Rebuild packages when dependencies that are used at both build-time and
-		run-time are upgraded.
+		Rebuild packages when build-time dependencies are upgraded.
 		"""
 
 		ebuilds = {
 			"sys-libs/x-1": { },
 			"sys-libs/x-1-r1": { },
 			"sys-libs/x-2": { },
-			"sys-apps/a-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
-			"sys-apps/a-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
-			"sys-apps/b-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
-			"sys-apps/b-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
+			"sys-apps/a-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
+			"sys-apps/a-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
+			"sys-apps/b-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
+			"sys-apps/b-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
 			"sys-apps/c-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
 			"sys-apps/c-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
 			"sys-apps/d-1": { "RDEPEND" : "sys-libs/x"},
 			"sys-apps/d-2": { "RDEPEND" : "sys-libs/x"},
-			"sys-apps/e-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
-			"sys-apps/f-2": { "DEPEND"  : "sys-apps/a", "RDEPEND" : "sys-apps/a"},
+			"sys-apps/e-2": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
+			"sys-apps/f-2": { "DEPEND"  : "sys-apps/a", "RDEPEND" : ""},
 			"sys-apps/g-2": { "DEPEND"  : "sys-apps/b sys-libs/x",
-				"RDEPEND" : "sys-apps/b"},
+				"RDEPEND" : ""},
 			}
 
 		installed = {
 			"sys-libs/x-1": { },
-			"sys-apps/a-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
-			"sys-apps/b-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
+			"sys-apps/a-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
+			"sys-apps/b-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
 			"sys-apps/c-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
 			"sys-apps/d-1": { "RDEPEND" : "sys-libs/x"},
-			"sys-apps/e-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : "sys-libs/x"},
-			"sys-apps/f-1": { "DEPEND"  : "sys-apps/a", "RDEPEND" : "sys-apps/a"},
-			"sys-apps/g-1": { "DEPEND"  : "sys-apps/b sys-libs/x",
-				"RDEPEND" : "sys-apps/b"},
+			"sys-apps/e-1": { "DEPEND"  : "sys-libs/x", "RDEPEND" : ""},
+			"sys-apps/f-1": { "DEPEND"  : "sys-apps/a", "RDEPEND" : ""},
+			"sys-apps/g-1": { "DEPEND"  : "sys-apps/b",
+				"RDEPEND" : ""},
 			}
 
 		world = ["sys-apps/a", "sys-apps/b", "sys-apps/c", "sys-apps/d",
 			"sys-apps/e", "sys-apps/f", "sys-apps/g"]
 
+
 		test_cases = (
 				ResolverPlaygroundTestCase(
-					["sys-libs/x"],
+					["sys-libs/x", "sys-apps/b"],
 					options = {"--rebuild-if-unbuilt" : True,
-						"--rebuild-exclude" : ["sys-apps/b"]},
-					mergelist = ['sys-libs/x-2', 'sys-apps/a-2', 'sys-apps/e-2'],
+						"--rebuild-exclude" : ["sys-apps/c"]},
+					mergelist = ['sys-libs/x-2', 'sys-apps/a-2', 'sys-apps/b-2',
+						'sys-apps/e-2', 'sys-apps/g-2'],
 					ignore_mergelist_order = True,
 					success = True),
 
 				ResolverPlaygroundTestCase(
-					["sys-libs/x"],
+					["sys-libs/x", "sys-apps/b"],
 					options = {"--rebuild-if-unbuilt" : True},
 					mergelist = ['sys-libs/x-2', 'sys-apps/a-2', 'sys-apps/b-2',
-						'sys-apps/e-2', 'sys-apps/g-2'],
+						'sys-apps/c-2', 'sys-apps/e-2', 'sys-apps/g-2'],
 					ignore_mergelist_order = True,
 					success = True),
 
@@ -72,27 +73,29 @@ class RebuildTestCase(TestCase):
 					success = True),
 
 				ResolverPlaygroundTestCase(
-					["sys-libs/x"],
+					["sys-libs/x", "sys-apps/b"],
 					options = {"--rebuild-if-unbuilt" : True,
 						"--rebuild-ignore" : ["sys-apps/b"]},
 					mergelist = ['sys-libs/x-2', 'sys-apps/a-2', 'sys-apps/b-2',
-						'sys-apps/e-2'],
+						'sys-apps/c-2', 'sys-apps/e-2'],
 					ignore_mergelist_order = True,
 					success = True),
 
 				ResolverPlaygroundTestCase(
-					["=sys-libs/x-1-r1"],
+					["=sys-libs/x-1-r1", "sys-apps/b"],
 					options = {"--rebuild-if-unbuilt" : True},
 					mergelist = ['sys-libs/x-1-r1', 'sys-apps/a-2',
-						'sys-apps/b-2', 'sys-apps/e-2', 'sys-apps/g-2'],
+						'sys-apps/b-2', 'sys-apps/c-2', 'sys-apps/e-2',
+						'sys-apps/g-2'],
 					ignore_mergelist_order = True,
 					success = True),
 
 				ResolverPlaygroundTestCase(
-					["=sys-libs/x-1-r1"],
+					["=sys-libs/x-1-r1", "sys-apps/b"],
 					options = {"--rebuild-if-new-rev" : True},
 					mergelist = ['sys-libs/x-1-r1', 'sys-apps/a-2',
-						'sys-apps/b-2', 'sys-apps/e-2', 'sys-apps/g-2'],
+						'sys-apps/b-2', 'sys-apps/c-2', 'sys-apps/e-2',
+						'sys-apps/g-2'],
 					ignore_mergelist_order = True,
 					success = True),
 
@@ -104,10 +107,11 @@ class RebuildTestCase(TestCase):
 					success = True),
 
 				ResolverPlaygroundTestCase(
-					["sys-libs/x"],
+					["sys-libs/x", "sys-apps/b"],
 					options = {"--rebuild-if-new-ver" : True},
 					mergelist = ['sys-libs/x-2', 'sys-apps/a-2',
-						'sys-apps/b-2', 'sys-apps/e-2', 'sys-apps/g-2'],
+						'sys-apps/b-2', 'sys-apps/c-2', 'sys-apps/e-2',
+						'sys-apps/g-2'],
 					ignore_mergelist_order = True,
 					success = True),
 
@@ -119,10 +123,11 @@ class RebuildTestCase(TestCase):
 					success = True),
 
 				ResolverPlaygroundTestCase(
-					["=sys-libs/x-1"],
+					["=sys-libs/x-1", "=sys-apps/b-1"],
 					options = {"--rebuild-if-unbuilt" : True},
 					mergelist = ['sys-libs/x-1', 'sys-apps/a-2',
-						'sys-apps/b-2', 'sys-apps/e-2', 'sys-apps/g-2'],
+						'sys-apps/b-1', 'sys-apps/c-2', 'sys-apps/e-2',
+						'sys-apps/g-2'],
 					ignore_mergelist_order = True,
 					success = True),
 			)
diff --git a/pym/portage/util/env_update.py b/pym/portage/util/env_update.py
index eb8a0d9..725b0d2 100644
--- a/pym/portage/util/env_update.py
+++ b/pym/portage/util/env_update.py
@@ -19,12 +19,14 @@ from portage.process import find_binary
 from portage.util import atomic_ofstream, ensure_dirs, getconfig, \
 	normalize_path, writemsg
 from portage.util.listdir import listdir
+from portage.dbapi.vartree import vartree
+from portage.package.ebuild.config import config
 
 if sys.hexversion >= 0x3000000:
 	long = int
 
 def env_update(makelinks=1, target_root=None, prev_mtimes=None, contents=None,
-	env=None, writemsg_level=None):
+	env=None, writemsg_level=None, vardbapi=None):
 	"""
 	Parse /etc/env.d and use it to generate /etc/profile.env, csh.env,
 	ld.so.conf, and prelink.conf. Finally, run ldconfig. When ldconfig is
@@ -39,6 +41,41 @@ def env_update(makelinks=1, target_root=None, prev_mtimes=None, contents=None,
 		defaults to portage.settings["ROOT"].
 	@type target_root: String (Path)
 	"""
+	settings = getattr(portage, 'settings', None)
+	if settings is None:
+		settings = config(config_root=target_root,
+			target_root=target_root)
+
+	if 'no-env-update' in settings.features:
+		return
+
+	if vardbapi is None:
+		if isinstance(env, config):
+			vardbapi = vartree(settings=env).dbapi
+		else:
+			if target_root is None:
+				target_root = portage.settings["ROOT"]
+			if hasattr(portage, "db") and target_root in portage.db:
+				vardbapi = portage.db[target_root]["vartree"].dbapi
+			else:
+				settings = config(config_root=target_root,
+					target_root=target_root)
+				target_root = settings["ROOT"]
+				if env is None:
+					env = settings
+				vardbapi = vartree(settings=settings).dbapi
+
+	# Lock the config memory file to prevent symlink creation
+	# in merge_contents from overlapping with env-update.
+	vardbapi._fs_lock()
+	try:
+		return _env_update(makelinks, target_root, prev_mtimes, contents,
+			env, writemsg_level)
+	finally:
+		vardbapi._fs_unlock()
+
+def _env_update(makelinks, target_root, prev_mtimes, contents, env,
+	writemsg_level):
 	if writemsg_level is None:
 		writemsg_level = portage.util.writemsg_level
 	if target_root is None:
-- 
1.7.3.1

